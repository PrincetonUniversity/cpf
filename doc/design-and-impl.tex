\section{Framework Design and Implementation}

\begin{figure}[htp]
  \includegraphics[width=\columnwidth]{figures/compiler-pipeline-crop}
  \caption{\name Framework Overview}
  \label{fig:compiler-pipeline}
\end{figure}

%\name enables efficient speculative parallelization by leveraging
%fine-grained combination of static analysis and cheap-to-validate
%assumptions.
%
\name is a framework for DOALL parallelization that incorporates the
ideas described in section~\ref{sec:approach}.


Figure~\ref{fig:compiler-pipeline} depicts an overview of the \name
framework, which includes a set of profilers, a parallelizing compiler,
and a runtime system.
%
The compilation flow begins with a preprocessing step that adds
instrumentation in the LLVM intermediate representation (IR) for
generating profiling results, from which a set of hot
loops is selected.
% In the second phase of the compilation, each hot
% loop is processed separately.
The speculation-aware memory analyzer
is queried to annotate the PDG with properties regarding dependences and
instructions. The applicability guard of each enabling
transformation examines the annotated PDG and creates transformation
proposals that offer to remove parallelization-inhibiting cross-iteration
dependences in the loop along with its cost. A DOALL planner considers
these proposals, selects set of minimum cost options and generates a sequence
of transformations, if a profitable DOALL plan is available.
Finally, we select a set of
compatible parallelizable loops with the maximum profitability, apply the
tranformations in their plans, and generate the parallel IR which is
then linked with the runtime and compiled as the parallel executable.

 This section begins with discussion of the planning phase which
 includes the main contributions of this paper and then subsequently
 describes other components of the framework.

\subsection{Speculation-Aware Memory Analyzer}
\label{sama}

%
% Prior techniques independently apply speculative techniques to
% overcome the imprecision of memory analysis, often leading to
% excessive use of expensive memory speculation.
%
%This work suggests that exposing cheap-to-validate speculative
%assumptions to static analysis can enable removal of memory
%dependences that would otherwise require memory speculation.
%
%This combination yields higher precision than using static analysis
%and these assumptions in a sequence.
%
%By making memory analysis aware of cheap-to-validate speculative
%assumptions,
%
%This work proposes a speculation-aware memory analyzer that
%combines the strengths of static analysis and cheap-to-validate
%speculative assumptions to reduce the need for expensive speculation by
%interpreting cheap-to-validate speculative assumptions as facts when memory
%analysis fails.
%%
%The inclusion of speculation changes the semantics of traditional
%memory analysis. It is now required to specify for each answer the
%speculative assumptions, if any, that were used in the process.
%%
%This differs from applying speculation and querying memory analysis again
%since the possibility of misspeculation restrains static analysis.

%When a query is received the memory analyzer tries to resolve it with
%usage of just static analysis. If that fails, it tries to use memory
%analysis with cheap-speculative assumptions.
%If that still fails then it resorts to memory speculation.
%
%
%Memory analysis annotates a PDG with information utilized by the
%decision making process in the rest of the planning phase.

Making memory analysis aware of cheap-to-validate speculation reduces the
need for expensive memory speculation.
\name's memory analysis is composed of many simple analysis algorithms
that collaboratively respond to queries (e.g.
CAF~\cite{johnson:cgo:17}).
%
The modularity of our static analysis simplifies the addition of
speculation awareness. Only the analysis algorithms that could
benefit from the collaboration need to be extended with a
speculative mode.
%
% A monolithic memory analysis would be harder to extend for speculation
% awareness.

In the speculation-aware memory analyzer, \name utilizes speculative
assumptions from two profilers: edge profiler (detects biased
branches) and loaded value predictor (predicts loaded values).
%
While use of these two speculative assumptions in conjuction with
static analysis already enables up to 2.5$\times$ improvement over a
system with no collaboration of memory analysis and speculation (see
~\cref{eval}), exposing even more cheap-to-validate speculative
assumptions to memory analysis could also be beneficial.  Such
exploration is left for future work.
%This paper just stratches the surface of this

\name uses edge profiling to produce a speculative control flow. This
speculative control flow can be used by memory analysis passes to
handle more queries.
%
Two examples of analysis passes that benefit from this speculative
information is kill-flow and unique access paths (UAP) algorithms.
%
Kill-flow analysis disproves memory dependences by finding killing
operations along all feasible paths between two operations.  If
kill-flow uses speculative control flow information, the feasible
paths are reduced and kill-flow asserts absence of a statically
non-disprovable memory dependence.
%
UAP collects a points-to set of objects for a pointer stored into a
non-captured memory location (i.e., address never stored into memory
and never passed to an externally defined function).
%Alias queries related to this memory location produce new alias
%queries for each value stored in this memory location.
Use of speculative control flow information enables detection of
speculatively dead stores in this set, decreasing its size and thus
simplifying alias queries for this pointer.

%In both examples, without speculative control flow awareness, prior
%speculative parallelization systems would be forced to use expensive
%memory speculation instead.

Regarding value prediction, if memory analysis passes assume that
loaded value predictions are correct, then they can re-interpret a
predicted load as a store of the predicted value. One analysis
algorithm that can benefit from that is again kill-flow. Kill-flow
treats the predictable load as a kill operation for must-aliasing data
flows.

%Apart from removal of dependences, the speculation-aware memory
%analyzer is also used to characterize dependences.
%%and dependent instructions.
%%
%Traditionally, dependence analysis (static, dynamic or speculative) in
%speculative parallelization only attempts to completely remove
%dependences.
%%
%If a dependence cannot be removed even with usage of speculation,
%because it is a real dependence that frequently manifests at runtime,
%no useful information is provided related to this dependence.
%%
%The memory analyzer though could still infer some useful property for
%this dependence or the dependent instructions.
%%
%This information is essential to enable certain transformations, such
%as the efficient variants of speculative privatization described in
%section ~\ref{novel_transf}.

The speculation-aware memory analyzer is queried to populate a program
dependence graph (PDG) annotated with information utilized by the rest
of the planning phase, namely by enabling transformations and the
planner. Annotations include properties for the dependences and the
dependent instructions.
%Note that traditional dependence analysis (static, dynamic or
%speculative) in speculative parallelization only attempts to
%completely remove dependences, while the speculation-aware memory
%analyzer infers properties for even non-removable ones.
If a property cannot be statically inferred, then annotations may
include alternatives; decision making is left for the planner.
%, which can perform global reasoning.
%The planner is responsible for selecting the most profitable option,
%taking into consideration. Memory analyzer has a limited scope.


\subsection{Enabling Transformations}
\label{enablers}

% Transformations modify the code to remove parallelization inhibitors.
%
All transformations in \name are split into two parts: (1) the applicability guard
that participates in the planning phase of the compilation, and (2) the
actual transformation that, if selected, is applied in the
transformation phase.
%This scheme seperates the desicion part from the actual
%transformation and allows us to evaluate the cost of each dependence
%separetely and
% This separation of decision making and application of transformations
This allows careful selection the most profitable plan instead of
applying a fixed
% (regardless of the input program)
set of enabling transformations and speculative techniques.

%Enabling transformations address memory, register or/and control
%cross-iteration dependences.
%
% This section focuses on memory related enabling transformations.
% Register and control cross-iteration dependence handling is discussed
% in section~\ref{design_transf}.

% \subsubsection*{Memory-related Enablers}

% To enable DOALL parallelization all cross-iteration memory dependences
% need to be addressed.  However, many enabling transformations operate
% at a memory object level. For example, the privatization
% transformation create private copies of memory objects. This motivates
% an object-centric approach.  Instead of targeting cross-iteration
% dependences, enabling transformation offer to handle a set of memory
% objects, in effect offer to address all their cross-iteration
% dependences.

%Characterizing the behavior of memory objects requires
%%(i) identification of accesses to this object within the loop and
%(i) mapping memory accesses to objects and (ii) analysis of the
%dependences that these accesses introduce.
%% characterize accesses
%This work attempts to satisfy these two requirements by using a
%combination of cheap-to-validate speculative assumptions and static
%analysis.
%
%The \textit{applicability} guard of an enabling transformation
%determines which memory objects have certain properties required by
%the transformation.
%
%examines the memory objects in the loop's memory footprint and
%determines which memory objects
%
%The applicability guard of a transformation determines, using the
%results of the speculation-aware memory analyzer,  which memory
%objects have certain properties required by the corresponding
%transformation and under which assumptions.
%%
%Assumptions are speculative information that require validation for
%the transformation to be correct, while applicability for a memory
%object means that the transformations can address all the
%cross-iteration dependences related to this memory object. \{\textbf{XXX}
%Pretty unclear what these two sentences means\}


%
\paragraph{Applicability:}
%
The applicability guard of a transformation uses the results of the
speculation-aware memory analyzer to determine which memory objects
satisfy the properties required by the transformation and records the
speculative assumptions used.
%
% XXX Make sure to add that assumptions need to be validated at runtime
% later on
% The applicability guard also records the speculative assumptions used
% to infer applicability for a memory object. These assumptions would
% need to be validated at runtime for the transformation to be correct.

\paragraph{Transformation proposal:} The output of each applicability
guard is assembled in a transformation proposal which is sent to the
DOALL planner (\cref{planner}).
%
The proposal includes for each memory object an estimated handling
cost based on the transformation itself and the validation cost of the
used speculative assumptions.
%
%The cost of each transformation is determined by the cost of the
%transformation itself and the cost of the speculative assumptions
%required for the transformation to be applicable.
%
For simplicity, each transformation and speculation
validation operation is assigned a fixed
%predefined
cost that ensures a basic ordering among the options. For
example,
%regarding speculative assumptions,
memory speculation has an extremely high cost (expensive validation),
loaded value prediction has a much smaller cost, while
control speculation has no cost.
%The estimated cost computation is very basic and just ensures basic
%ordering among the options.
%
%Every transformation is assigned an arbitrary cost that ensures some
%ordering among transformation. Speculative assumptions is similarly
%computed.
%
For the set of transformations and speculative assumptions in our
framework and in the context of DOALL parallelization, this simplified
cost model proved sufficient for detection of minimal cost plans.
%
%A more complex cost model, that would allow more elaborate decision
%making, is left for future work.

%
%
%which speculative assumptions need to be validated for the
%transformation to be correct.
%
%Object-centric transformation.  All memory objects need to be handled
%by a transformation.
%
%each access of the memory object should preserve the property
%
%Finally, each transformation
%includes in its proposal the set of speculative assumptions validation
%necessary for each memory object for the transformation applicability
%to be correct.

\paragraph{Transformation Application:}
Each transformation reallocates
memory objects it is selected to handle
%If, during the planning phase, a transformation is selected for a set
%of memory objects, then during the code transformation phase, the
%transformation separates these objects
to its own heap, disjoint from any others; transformations may also
perform additional transformation-specific modifications.

Separating the objects is essential
for two reasons. First, each transformation may demand different
memory mapping semantics and handles objects differently at commit.
Second, mapping of memory accesses to
objects often relies on profiling information, especially in languages with
unrestricted pointers like C/C++. Ensuring that all objects' accesses
are contained within a transformation's heap is sufficient to
validate underlying object assumptions. This idea of separation has
been explored previously by Johnson et al. (Privateer~\cite{johnson:12:pldi}).
The speculative assumptions used for each selected transformation also need
to be validated at runtime to ensure correctness.
% The applicability guard also records the speculative assumptions used
% to infer applicability for a memory object. These assumptions would
% need to be validated at runtime for the transformation to be correct.
%Separation checks are required for memory accesses whose underlying
%objects are discovered via profiling.
%The runtime function for re-allocation of memory objects can be
%specialized by each transformation.
%
%Each transformation has its own runtime support for handling its
%objects during execution.

%The idea of separating memory objects has been explored previously by
%Johnson et al. (Privateer~\cite{johnson:12:pldi}).  However, Privateer
%employs a monolithic design that entangles classification of memory
%objects with memory speculation and other
%%monolithic design of memory object classification entangles
%%separation speculation with memory speculation and other
%profiling-based information, resulting in unnecessarily high runtime
%overheads (see example in section~\ref{motiv_example} and performance
%analysis in section ~\ref{eval}).
%%
%By contrast, \name employs a modular and extensible design that
%facilitates planning and selection of minimal cost solutions without
%unnecessary speculation.
%where enabling transformations offer to handle memory objects along
%with estimated costs -offers with costs and the selection happens.
%

%Every transformation can optimize the checks that are applied to its
%objects knowing that there is no aliasing with other objects handled
%by different transformations.

%ensures that all accesses of a memory object have the required
%properties.

% We describe in the next section efficient variants of the speculative
% privatization transformation, which constitute a contribution of this
% paper.  Other enabling transformations that are used in our framework
% but have been proposed in prior work are discussed in
% section \ref{design_transf}.
We propose the following enabling transformations for addressing memory,
register, and/or control cross-iteration dependences.

\input{transformations}

%\subsubsection{Efficient Speculative Privatization Variants}
\subsubsection{New Enablers}
\label{novel_transf}

%Ensuring correct live-out memory state often requires extensive bookkeeping,
%during parallel execution, for the write footprint of private objects. To make
%parallelization more \textit{profitable}, this work expresses more properties
%for private memory objects. Private objects could additionally (a) be
%independent~\cite{ARRAY_privatization} (no loop-carried false dependences); (b)
%have loop-invariant condition for last update within the
%loop~\cite{ARRAY_privatization}; (c) have predictable live-out content;
%%(not found in prior work);
%or (d) have only local accesses (allocated outside the loop, but all
%accesses are contained within the loop execution).
%%
%%Private properties (a), (b) have been explored before in the context of static
%%parallelization~\cite{ARRAY_privatization}, but never before in speculative
%%parallelization systems (maybe in LRPD). No prior work leveraged property (c).
%%
%

% We first discuss speculative privatization as it appears in prior work
% and then describe new variants that perform more efficient
% privatization.

% This section describes the behavior of the new enablers introduced in
% \cref{new_enablers}.
% Prior software speculative systems with extended support for
% privatization~\cite{johnson:12:pldi,kim:12:cgo} only infer the basic
% privatization property that there are no cross-iteration data flows
% for a memory object.
%
% Speculative privatization application involves instrumentation of all
% write accesses of privatized objects for costly logging or
% communication. At commit, the private copies of each worker are merged
% according to metadata that specify which worker wrote each byte last.

To avoid expensive monitoring of write sets during parallel execution
and minimize copy-out costs, we propose four efficient variants of
this transformation, introduced in \cref{new_enablers}. This section
describes the behaviors of each of them at runtime.
%
% To be applicable, these variants require apart from the basic
% privatization property additional memory object properties.

%Table~\ref{tab:priv_types} summarizes how these properties can facilitate more
%efficient parallelization compared to just inferring that a memory object is
%private. In short, inference of any of these four private properties allows
%complete elimination of bookkeeping and access checks. Prior software
%speculative systems with extended support of privatization (Privateer~\cite{},
%ClusterDoall~\cite{}) are only able to infer the simple private property and
%thus always require costly checks or monitoring.

\begin{itemize}
%
\item \textbf{Independent:} This transformation's heap is shared
  among all parallel workers, since there is no overlapping memory
  accesses.
  %
  No monitoring of write sets is needed. At commit the heap is copied-out
  to the non-speculative state.
%
%If the selected parallelization plan is non-speculative, then this
%heap is also shared with the main process and copy-in and copy-out
%overheads are eliminated as well.

%Behavior : No write set monitoring performed. Memory object is shared among parallel workers.

\item \textbf{Overwrite Private:} This transformation's heap has
  CoW (copy-on-write) mapping. At the end of the parallel
  invocation the last executed iteration
  state is copied-out and no monitoring is needed.

%Additional applicability guard:
%object has loop-invariant condition for last update within the loop.
%
%Behavior: No write set monitoring performed. The live-out state for
%object with this property is the memory state of the last iteration
%executed before commit.

\item \textbf{Predictable Private:} This transformation's heap
  has CoW mapping. The live-out state is predictable, so no monitoring
  or merging of parallel workers state is needed. This transformation
  relies on value prediction's speculative assumptions.

\item \textbf{Local Private:} This transformation's heap has
  CoW mapping and there is no need for copy-out or monitoring.

\end{itemize}

The first two variants have been explored by Tu et
al.~\cite{tu:94:lcbc} but were limited to static analysis
based detection of privatization. Unlike prior work, \name
extends applicability of these variants with usage of speculative
assumptions to programs with pointers, dynamic allocation, and type
casts.

%\input{private_types}

\subsection{DOALL planner}
\label{planner}
\input{planner}

\subsection{Profiling}
%\subsection{Speculative Assumptions}

\name uses a set of profilers to generate speculative assumptions:
%
(i) an edge profiler~\cite{LLVM:CGO04} that identifies biased
branches and produces a speculative control flow;
%
(ii) a memory flow dependence profiler~\cite{chen:04:cc} that asserts
the absence of non-observed data flows;
%
(iii) a value-prediction profiler ~\cite{gabbay:97:micro} that detects predictable loads;
%
(iv) a pointer-to-object profiler ~\cite{johnson:12:pldi}
that produces a points-to map that for allows detection of underlying objects
for every memory access; and,
%
(v) an object lifetime profiler ~\cite{johnson:12:pldi}
that detects short-lived memory objects, namely objects that exist only within a
single loop iteration.
%

\subsection {Static Analysis}
\input{analysis}

% \subsection{Enabling Transformations}
% \label{design_transf}
% \input{transformations}


\subsection{Preprocessing}

The compilation process begins with a preprocessing step that
generates the targeted for parallelization intermediate representation
(IR) of the program. We use Clang~\cite{LLVM:CGO04} to generate LLVM IR
from the sequential C/C++ programs followed by LLVM IR optimizations.
We then perform a pass of selective profile-guided
inlining and finally another round of LLVM IR optimizations to produce
the target LLVM IR that is used as the starting point for the rest of
the compilation process.

\subsubsection{LLVM optimizations}

Transformations in this preprocessing step are crucial for the
applicability and profitability of parallelization.
%
Parallelizing compilers usually compile the source code with the \textit{-O3}
flag to get the initial IR and then perform a few additional
passes.
% XXX Doesn't sound vague at all...
However, traditional compiler transformations are meant for optimized
sequential execution.
%
Some of these optimizations could unnecessarily complicate the code
and block parallelization efforts.
%
Any performance improvements from these optimizations are negligible
compared to the benefits of successful parallelization.
%
For example, LLVM tries to sink common instructions from two different
execution paths. This reduces the code size but when applied to memory
operations, it complicates the inference of the underlying objects.
%
To avoid such problems, \namensp 's preprocessing step only applies a
small set of LLVM IR enabling transformations that simplify and
canonicalize the IR.

%Contrary to LLVM (version 5.0.2) IR optimizations, frontend optimizations by Clang can
%be applied more freely.
%%
%If Clang optimizations are not applied, some information extracted
%from the source code may be omitted from the generated LLVM IR.  In
%fact, we noticed that when no optimization is used in the frontend
%(\textit{clang -O0 -Xclang -disable-O0-optnone}), some very helpful
%LLVM intrinsics (e.g., lifetime start/end intrinsics for stack
%allocations) are lost.  To avoid this, we compile with \textit{-O1} flag for
%frontend optimizations but disable LLVM optimizations (\textit{-O1
%-Xclang -disable-llvm-passes}).


\subsubsection{Profile-Guided Selective Inlining}

% Interprocedural analysis is complicated and expensive, restricting the
% precision or scalability of static analysis.
%
Dependences involving callsites often prevent parallelization or lead
to extensive usage of expensive-to-validate memory flow speculation.
%
Inlining can mitigate this problem, but the heuristics used in
industrial compilers that determine whether to inline or not are tailored
for sequential code optimization and are mostly irrelevant to
effective parallelization.
%
% code size expansion
%When parallelization is applicable, these
%
%More aggressive inlining is needed for parallelization. Naive
%aggressive inlining, though, would lead to code size explosion and
%exponential increase in compilation time so avoiding inlining in some
%cases
%%Filtering of some callsites
%is still essential.
%

\name uses profile information to detect hot loops and speculatively
dead callsites. Only callsites that are within these hot loops and
that cannot be speculated away with control speculation are inlined.
%
Of these callsites, \name also avoids inlining ones that do not
sink or source cross-iteration dependences that inhibit DOALL
parallelization.
%
%just get a summary.  hard to handle them separetely end up
%overspeculating because it is hard to find the problem.

%Inlining is also sometimes useful outside the hot loops.
%%
%Static analysis can easily infer alias and underlying object queries
%for global variables whose address is never
%captured~\cite{johnson:14:pldi}. However, if the address of a global
%variable is passed as an argument to a function, then analysis in
%most cases conservatively assumes that the address is stored in memory
%(i.e. captured) within the function. Inlining diminishes this
%problem.


\subsection{Loop Selection} An execution time profiler, similar to
gprof~\cite{gnu:binutils:web}, finds hot loops that execute for at least 10\%
of the total program execution.
%
% For each hot loop, the compiler finds a DOALL parallelization plan and
% estimates its profitability.
%
Out of the profitably parallelizable loops, certain loops are not
selected for parallelization. The excluded loops are either
simultaneously active with another more profitable loop (we do not
support nested parallelism) or their memory object assignments
conflict with the assignments of a more profitable loop (every memory
object can be allocated to only one heap throughout the program in our
current implementation).

\input{runtime2}

%In this work, we introduce a set of transformations to explore more
%opportunities of parallelization.
%
%%We call these enabling transformations Enablers.
%
%%  How to query Enabler?
%
%One thing that hinders these Enablers from working coordinately is
%the phase-ordering problem, which means one transformation could be disabled
%by a previous transformation. Another problem is the increasing
%implementation and maintainance difficulty when more and more Enablers are
%put in the framework. To avoid these problems, we carefully organize the
%framework in a way that all Enablers are modular and independent. As a first
%step, all loop-carried dependences are identified by the frontend and passed
%to each Enabler, who tries to address each dependence by its best effort and
%returns a remedy along with the cost if a way to remove the dependence is
%available. If all dependences are removable by at least one Enablers, the
%parallel code generation part will choose the remedy with the lowest cost
%for each dependence and generate the parallel binary. This scheme seperates
%the desicion part from the actual transformation and allows us to evaluate
%the cost of each dependence separetely and choose the most profitable plan
%instead of applying all transformations in a fixed order. For simplicity, we
%assigned to each Enabler a predefined cost in this work. Yet in Table.
%\ref{table:enabler-stats}, we provided the statistics of the applicable and
%chosen Enabler to show how this framework makes the tradeoff when more than
%one Enablers are available. This study is not available for a traditional
%approach of transformations.
%
%The analysis passes and the transformation passes are seperated. Even though
%it has been suggested before, in this work, we have a smaller set of
%Enablers with stronger capability.

%\textbf{Non-Speculative Transformations}
%
%\begin{itemize}
%    \item Conservative Reduction (ReduxRemed)
%        % Both scalar and memory reduction
%
%    \item Conservative Privatization (PrivRemed)
%        % Removes loop-carried false memory dependences on conservatively provable privitizable objects
%
%    \item Memory Versioning (MemVerRemed)
%        % Assumes privatized memory for each thread
%        % Removes loop-carried false memory dependences
%        % Stronger but more expensive than PrivRemed
%        % Process-based parallelization enforces this remediator
%
%    % \item Counted Loop Detection (CountedIVRemed)
%        % Removes loop-carried register and control dependences related to induction variables on counted loops
%
%    \item TXIO (TXIORemed)
%        % I/O deferral
%        % Delays execution of instructions with side-effects, such as I/O operations
%
%    % \item Conservative Loop Fission (LoopFissionRemed) ???
%        % Separate non-DOALL SCCs to an initial sequential stage (loop in this case)
%        % Only small sequential stages considered
%        % No usage of speculative remediators to achieve separation
%\end{itemize}
%
%\textbf{Speculative Transformations}
%
%\begin{itemize}
%    \item Control Speculation (ControlSpecRemed)
%        % Based on edge profile info, removes control flow edges and considers all basic blocks dominated by these edges as speculatively dead
%        % Inexpensive runtime validation
%
%    \item Value Prediction (LoadedValuePred)
%        % Some load instructions always read a single, predictable value from memory
%        % Loop-Invariant Loaded-Value
%        % Inexpensive runtime validation
%
%    \item Header-phi prediction (HeaderPhiPredRemed)
%        % Some phi instructions have a predictable value.
%        % Allows removal of loop-carried register dependeces
%        % Inexpensive runtime validation
%
%    \item Separation Speculation (LocalityRemed)
%
%        % Johnson et al. PLDI '12
%
%        % Separation speculation partitions a program's allocations into a few disjoint "families" of objects and speculatively assumes that every pointer in the program refers exclusively to objects in one family. Under this assumption, if two pointers reference distinct families, they cannot alias.
%
%        % Relatively inexpensive runtime validation due to small number of families, allocation of objects in family-specific memory regions, runtime optimizations and thread-local checks (no communication among concurrent threads needed).
%
%        % Secondary speculation built on top of separation speculation:
%
%        %     Read-only speculation
%        %         Read-only family
%        %         Some memory objects are never modified but static dependence analysis is sometimes unable to prove this property
%        %         Objects in the read-only family are only accessed by read-only memory operations. Thus, speculatively read-only memory operations never experience flow, anti or output dependences
%        %         Apart from separation speculation validation, no other validation is required
%
%        %     Speculative accumulator expansion
%        %         Compiler identifies accumulators as values which are repeatedly updated with an associative and commutative operator (a reduction) but whose intermediate values are otherwise unused within the loop. Static dependence sometimes fails to prove that every access to a given storage location is a reduction or that intermediate values are never used.
%        %         The pointer-family assumption establishes that objects in the reduction family are only accessed by load-reduce-store sequences and consequently that intermediate values cannot be otherwise observed or modified.
%        %         Apart from separation speculation validation, no other validation is required
%
%        %     Speculative privatization
%        %         Reuse of data structures with no flow dependences from one iteration to the other prevents parallelization due to anti or output dependences.
%        %         Addressed by having a private copy of the data structure for each iteration
%        %         Assumption: loads from certain private objects never read values stored during earlier iterations of the loop.
%        %         Privatization criteria validated in two phases, one thread-local and one more expensive that requires communication among threads.
%
%        %     Object-lifetime speculation
%        %         Short-lived objects
%        %         Some objects allocated within a loop iteration are always deallocated before the end of that same iteration. Static dependence analysis often fails to identify this case.
%        %         Loads from or stores to such objects cannot depend on memory accesses in other iterations.
%        %         Extra validation on top of separation speculation validation: object lifetime speculation must validate that short-lived objects never outlive their iteration. Thread-local checks.
%
%    \item Memory Flow Speculation (SmtxSlampRemed \& SmtxLampRemed)
%        % Assumes the absence of flow dependences between memory operations when not manifested during profiling.
%        % Provides as much or more an enabling effect than many other types of speculation.
%        % Expensive validation. Requires communication among concurrent threads.
%
%    \item Speculative AA stack (MemSpecAARemed)
%        % Allows collaboration among memory flow speculation, control speculation, value prediction, speculative points-to analysis and static analysis.
%        % Demonstrates the power of collaboration among remediators, and between speculation techniques and static analysis.
%        % Provides at least as much coverage as all the remediators addressing mem deps combined (only excludes SLAMP mem spec and localityaa).
%
%    % \item Speculative Loop Fission (LoopFissionRemed) ???
%        % Same as Conservative Loop Fission apart from the fact that it requires usage of speculative remediators to achieve separation
%
%    \item Pointer-Residue Speculation (PtrResidueRemed)
%        % Never part of a paper. Never evaluated. Idea published in Nick Johnson's thesis
%        % Separation speculation disambiguates references to different objects, but does not disambiguate references within the same object. Pointer-residue speculation works at the sub-object level.
%        % It disambiguates different fields within an object and in some cases recognizes different regular strides across an array.
%        % It characterizes each pointer expression in the program according to the possible values of its four least-significant bits (residue).
%        % Examines whether residue sets are disjoint with respect to the size of the memory accesses of two given operations.
%\end{itemize}
%
%Second Level Enabler
%\begin{itemize}
%    \item Replicable Stage (RepStageRemedy)
%\end{itemize}
%
%\subsection{Enabler Statistics}
% Insert the table here

% \includegraphics[width=\textwidth]{figures/table.png}
% \label{table:enabler-stats}


% \begin{table}[]
% \label{table:enabler-stats}
% \begin{tabular}{lllllllllllllll}

% Dep Type & Remedy Type/Bmark+loop    & doitgen & 3mm   & dijkstra-dynsize &
% 470.lbm & swaptions & covariance & blackscholes & enc-md5 & 179.art & gemm  &
% correlation & 052.alvinn & 2mm   \\

% ctrl     & ctrl-spec-remedy          & 0/26    & 0/16  & 184/276          &
% 0/102   & 6630/7020 & 0/19       & 0/28         & 0/150   & 0/249   & 0/17  &
% 0/20        & 0/91       & 0/17  \\

%          & replicable-stage-remedy   & 26/26   & 16/16 & 92/92            &
%          102/102 & 390/390   & 19/19      & 28/28        & 150/150 & 249/249 &
%          17/17 & 20/20       & 91/91      & 17/17 \\

% raw      & smtx-lamp-remedy          & 0/0     & 0/0   & 0/62             & 0/0
% & 0/873     & 0/0        & 0/1          & 0/70    & 0/51    & 0/0   & 0/0
% & 0/26       & 0/0   \\
%          & ctrl-spec-remedy          & 0/0     & 0/0   & 14/23            & 0/0
%          & 0/0       & 0/0        & 1/2          & 0/1     & 16/39   & 0/0   &
%          0/0         & 0/0        & 0/0   \\

%          & txio-remedy               & 0/0     & 0/0   & 25/25            & 0/0
%          & 0/0       & 0/0        & 1/1          & 0/0     & 23/23   & 0/0   &
%          0/0         & 0/0        & 0/0   \\

%          & locality-redux-remedy     & 0/0     & 0/0   & 0/0              & 0/0
%          & 0/0       & 0/0        & 0/0          & 0/0     & 0/0     & 0/0   &
%          0/0         & 10/10      & 0/0   \\

%          & locality-local-remedy     & 0/0     & 0/0   & 28/39            & 0/0
%          & 873/873   & 0/0        & 0/0          & 0/0     & 0/0     & 0/0   &
%          0/0         & 0/0        & 0/0   \\

%          & locality-private-remedy   & 0/0     & 0/0   & 10/22            & 0/0
%          & 0/0       & 0/0        & 0/0          & 0/0     & 36/43   & 0/0   &
%          0/0         & 11/11      & 0/0   \\

%          & locality-separated-remedy & 0/0     & 0/0   & 0/0              & 0/0
%          & 0/0       & 0/0        & 0/0          & 0/0     & 3/3     & 0/0   &
%          0/0         & 6/6        & 0/0   \\

%          & locality-subheaps-remedy  & 0/0     & 0/0   & 0/0              & 0/0
%          & 0/0       & 0/0        & 0/0          & 0/0     & 0/0     & 0/0   &
%          0/0         & 1/1        & 0/0   \\

%          & redux-remedy              & 0/0     & 0/0   & 0/0              & 0/0
%          & 0/0       & 0/0        & 0/0          & 1/1     & 0/0     & 0/0   &
%          0/0         & 0/0        & 0/0   \\

%          & mem-spec-aa-remedy        & 0/0     & 0/0   & 0/73             & 0/0
%          & 0/873     & 0/0        & 0/2          & 0/70    & 0/80    & 0/0   &
%          0/0         & 0/28       & 0/0   \\

%          & ptr-residue-remedy        & 0/0     & 0/0   & 0/14             & 0/0
%          & 0/0       & 0/0        & 0/0          & 0/0     & 1/1     & 0/0   &
%          0/0         & 0/0        & 0/0   \\

% waw      & smtx-lamp-remedy          & 0/0     & 0/0   & 0/0              & 0/0
% & 0/0       & 0/0        & 0/0          & 0/4     & 0/0     & 0/0   & 0/0
% & 0/0        & 0/0   \\

%          & mem-ver-remedy            & 0/0     & 0/0   & 0/94             & 0/0
%          & 0/540     & 0/1        & 0/3          & 0/14    & 0/114   & 0/0   &
%          0/4         & 0/14       & 0/0   \\

%          & priv-remedy               & 0/0     & 0/0   & 8/8              & 0/0
%          & 0/9       & 1/1        & 0/0          & 0/4     & 19/23   & 0/0   &
%          4/4         & 3/5        & 0/0   \\

%          & ctrl-spec-remedy          & 0/0     & 0/0   & 19/28            & 0/0
%          & 0/0       & 0/0        & 1/2          & 0/1     & 17/38   & 0/0   &
%          0/0         & 0/0        & 0/0   \\

%          & txio-remedy               & 0/0     & 0/0   & 25/25            & 0/0
%          & 0/0       & 0/0        & 1/1          & 0/0     & 21/21   & 0/0   &
%          0/0         & 0/0        & 0/0   \\

%          & locality-redux-remedy     & 0/0     & 0/0   & 0/0              & 0/0
%          & 0/0       & 0/0        & 0/0          & 0/0     & 0/0     & 0/0   &
%          0/0         & 8/8        & 0/0   \\

%          & locality-local-remedy     & 0/0     & 0/0   & 17/35            & 0/0
%          & 540/540   & 0/0        & 0/0          & 0/0     & 0/0     & 0/0   &
%          0/0         & 0/0        & 0/0   \\

%          & locality-private-remedy   & 0/0     & 0/0   & 10/33            & 0/0
%          & 0/0       & 0/1        & 0/1          & 0/0     & 55/77   & 0/0   &
%          0/4         & 3/6        & 0/0   \\

%          & redux-remedy              & 0/0     & 0/0   & 0/0              & 0/0
%          & 0/0       & 0/0        & 0/0          & 1/1     & 0/0     & 0/0   &
%          0/0         & 0/0        & 0/0   \\

%          & mem-spec-aa-remedy        & 0/0     & 0/0   & 0/78             & 0/0
%          & 0/540     & 0/1        & 0/3          & 0/3     & 0/114   & 0/0   &
%          0/4         & 0/14       & 0/0   \\

%          & ptr-residue-remedy        & 0/0     & 0/0   & 0/4              & 0/0
%          & 0/0       & 0/0        & 0/0          & 0/0     & 0/0     & 0/0   &
%          0/0         & 0/0        & 0/0   \\

% war      & smtx-lamp-remedy          & 0/0     & 0/0   & 0/0              & 0/0
% & 0/0       & 0/0        & 0/0          & 0/4     & 0/0     & 0/0   & 0/0
% & 0/0        & 0/0   \\

%          & mem-ver-remedy            & 0/0     & 0/0   & 43/69            & 0/0
%          & 780/780   & 0/0        & 0/1          & 132/132 & 59/82   & 0/0   &
%          0/0         & 23/23      & 0/0   \\

%          & ctrl-spec-remedy          & 0/0     & 0/0   & 0/12             & 0/0
%          & 0/0       & 0/0        & 0/1          & 0/0     & 0/37    & 0/0   &
%          0/0         & 0/0        & 0/0   \\

%          & txio-remedy               & 0/0     & 0/0   & 26/26            & 0/0
%          & 0/0       & 0/0        & 1/1          & 0/0     & 23/23   & 0/0   &
%          0/0         & 0/0        & 0/0   \\

%          & locality-redux-remedy     & 0/0     & 0/0   & 0/0              & 0/0
%          & 0/0       & 0/0        & 0/0          & 0/0     & 0/0     & 0/0   &
%          0/0         & 0/5        & 0/0   \\

%          & locality-local-remedy     & 0/0     & 0/0   & 0/20             & 0/0
%          & 0/780     & 0/0        & 0/0          & 0/0     & 0/0     & 0/0   &
%          0/0         & 0/0        & 0/0   \\

%          & locality-private-remedy   & 0/0     & 0/0   & 0/21             & 0/0
%          & 0/0       & 0/0        & 0/0          & 0/0     & 0/45    & 0/0   &
%          0/0         & 0/11       & 0/0   \\

%          & locality-separated-remedy & 0/0     & 0/0   & 0/0              & 0/0
%          & 0/0       & 0/0        & 0/0          & 0/0     & 0/3     & 0/0   &
%          0/0         & 0/6        & 0/0   \\

%          & locality-subheaps-remedy  & 0/0     & 0/0   & 0/0              & 0/0
%          & 0/0       & 0/0        & 0/0          & 0/0     & 0/0     & 0/0   &
%          0/0         & 0/1        & 0/0   \\

%          & mem-spec-aa-remedy        & 0/0     & 0/0   & 0/52             & 0/0
%          & 0/780     & 0/0        & 0/1          & 0/2     & 0/82    & 0/0   &
%          0/0         & 0/23       & 0/0   \\

%          & ptr-residue-remedy        & 0/0     & 0/0   & 0/7              & 0/0
%          & 0/0       & 0/0        & 0/0          & 0/0     & 0/1     & 0/0   &
%          0/0         & 0/0        & 0/0   \\

% reg      & redux-remedy              & 0/0     & 0/0   & 0/0              & 0/0
% & 0/0       & 0/0        & 0/0          & 0/0     & 0/0     & 0/0   & 0/0
% & 1/1        & 0/0   \\

%          & replicable-stage-remedy   & 1/1     & 1/1   & 2/2              & 1/1
%          & 1/1       & 1/1        & 1/1          & 5/5     & 2/2     & 1/1   &
%          1/1         & 1/1        & 1/1
% \end{tabular}
% \end{table}

% Discussion of the table


