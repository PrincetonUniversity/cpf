The runtime system of \name provides several features that allows for
low overheads for both speculative and non-speculative parallelization.

% Something about how killpriv only needs to copy out last checkpoint's
% values to main and no merging of checkpoints needed
\paragraph{Process spawning}
We use a process-based parallelism scheme as opposed to a thread-based one
for several purposes. The runtime system \texttt{\textbf{fork()}}s all the processes
only once at program startup to avoid the overhead of spawning at every loop
invocation, especially important for programs whose inner loops are
parallelized, such as \texttt{052.alvinn}. Each worker process waits for the main
process to send only the function to run, the starting iteration, and the
size of each heap.

\paragraph{Shared memory}
At program startup, the main process creates and maps several regions of named shared
memory, with shared permissions, in \texttt{\textbf{/dev/shm}} corresponding
to the heaps of each enabling transformation.
When a worker starts an invocation, it remaps these regions of memory to
disjoint segments in its own virtual memory space with either
copy-on-write, shared, or read-only semantics depending on the heap.
This in effect communicates all the live-in values from the
main process to the workers in an efficient manner.

\paragraph{Checks and Checkpoints}
For speculatively applied transformations, heap checks are inserted to
ensure that objects remain in the same heap as recorded from profiling or
inferred from analysis. The separation of memory regions allows these
checks to be very cheap, only needing to perform a bitwise OR of an
object's address with the most significant 4 bits of its heap's address.

Each enabling transformation has its own specialized runtime calls for logging
and checking reads of and writes to objects of its heap; these calls are
specialized to reduce the overhead for transformations that do not require
as extensive logging as others \{\textbf{XXX} Look at transformations to
make sure this matches what it says\}. Every 252 iterations, assuming no
misspeculation is detected by a worker, a checkpoint operation is performed.
This operation reconciles all the workers' logs and checks for
misspeculation that may have occurred between workers and merges with any
previous checkpoints, if any exist. The cost of the checkpoint depends on
the enabling transformations used (e.g. Known Last Iteration Update has no
checkpoint cost) and the size of each object in each of the corresponding heaps.
The most recent checkpoint will only contain the last valid program state
for use in the case of misspeculation.

% In addition to a heap check, each worker also performs a privacy check on every
% private read or write to an
% address with any of its accesses to the same address in a previous
% iteration. It will also log in the shadow memory either the iteration of the
% access in the case of a private write or a fixed value indicating a
% private read occurred. Any violation of the privacy property will trigger a
% misspeculation and a jump to recovery code. As \name enforces this
% property at the byte-level, we perform a checkpoint every 252 iterations
% before the shadow memory's iteration counter can overflow (255 possible
% values per byte minus some values with fixed meaning \{XXX is this
% clear?\}). The checkpoint reconciles all the worker's logs and checks for
% misspeculation between iterations of different workers \{reword this???\} and
% merges with previous checkpoints to save the current program state in the
% case of misspeculation during the next checkpoint chunk. The overhead for
% checkpointing is mainly dependent on the size of the reduction and private heaps,
% as merging them requires performing the reduction or validation of privacy,
% respectively.

% \paragraph{Misspeculation}
% In the case of misspeculation, the workers will attempt to get to the last
% checkpoint before the misspeculated iteration. The main process will run,
% using the checkpoint as its program state, the sequential version of the
% loop until after the misspeculated iteration. The parallel version of the
% loop will then resume.

\paragraph{Handling live-out values}
At the end of a loop invocation, or in the case of misspeculation, the main
process will copy values out from the last committed checkpoint object. For
programs that have many live-out objects, this operation may reduce the
achievable speedup as it is inherently sequential.

% As static analysis is used in conjunction with memory speculation, we can
% infer that some benchmarks that were tested do not require any speculation.
% We reallocate statically private objects (is this a thing?) to a new heap,
% \texttt{KILL\_PRIVATE}, that does not require checks or logs on accesses or
% merging during checkpoints. This allows us to reduce the overhead
% drastically for non-speculative programs to achieve linear speedup.

% handling of live-ins, LC, live-outs

% lightweight,
% unified for both spec and non-spec


%The runtime system provides efficient mechanisms for replication of objects to
%support privatizationand for recovery from misspeculation
%
%By maintain-ing the same virtual address space with different mappings to
%phys-ical memory, the workers are able to operate on their privatemem-ory
%without  much  performance  penalty,  with  physical  pages  be-ing
%privatizedon-demandusing the Copy-On-Write mechanism
