\section{Introduction}

% AutoPar is important.
%Coincident with the introduction of multicore, the processor industry has
%fallen well short of the decades-old single-threaded performance growth
%trend. The burden of extracting sufficient multicore-appropriate parallelism
%to overcome this sequential performance deficit has fallen on programmers
%and compilers. Yet, despite many new tools, languages, and libraries
%designed for multicore, the difficulty of parallelism extraction keeps
%multicore grossly underutilized.

%Parallelization is necessary

Multicore architectures are ubiquitous in systems ranging from mobile to
"warehouse scale`` systems. Thus, parallelism is more important than ever to
harvest more performance from current hardware.  This burden of extracting
sufficient parallelism has fallen on programmers and compilers. Yet, despite
many new tools, languages, and libraries designed for multicore, multicore
remains a grossly underutilized technology.


%Programmers?

%There are many ways programmers can manually realize parallelism.  Common
%approaches, such as PThreads~\cite{pthread:web},
%Map-Reduce~\cite{dean:08:cacm}, and OpenMP~\cite{openmp:web}, generally help
%programmers extract coarse grained parallelism (CGP) from hot loops in
%applications.
Manually expressing parallelism is tedious and error-prone. The programmers that
do attempt parallelism typically rely on popular approaches (e.g.,
PThreads~\cite{pthread:web}, Map-Reduce~\cite{dean:08:cacm}, and
OpenMP~\cite{openmp:web}) that focus on extracting coarse grained parallelism
(CGP) from hot loops in applications.
%
CGP can be extremely beneficial in cluster and warehouse-scale systems, but has
limitations on multicore.  Programs with CGP are not ideally suited for
multicore as they tend to stress multicore's shared resources, such as caches
and memory bandwidth.  Google revealed, in a candid disclosure, that their
multicore utilization rarely exceeds 20\%~\cite{barroso:07:computer}. Other
researchers have also subsequently corroborated this
observation~\cite{chung:13:isca}.
%
Asking programmers to address this underutilization with finer-grained
parallelism extraction would result in enormous increase in programmer effort.
%
Moreover, for programs with complex control and data flow, even CGP extraction
can be very difficult, and most such programs remain without a CGP extracted
version.

%autopar is very useful
Automatic parallelization is an attractive approach to make efficient use of
multicore systems, yielding improved performance even in already parallelized
applications (e.g, reduced maximum latency on each parallel task of a
CFG-parallelized application). Unfortunately, even after 15 years of multicore,
automatic parallelization is still mostly limited to scientific and
data-intensive applications.
%the routine extraction of TLP remains elusive.

%analyis limitations
Major impediments to automatic parallelization are the limitations of static
analysis. Static dependence analysis (including alias analysis and control flow
analysis) are undecidable and difficult in practice, and so compilers rely upon
imprecise static analysis that is insufficient to enable parallelization of
general-purpose programs by itself.
%Static analysis alone is simply too imprecise to enable aggressive
%parallelization.
Even if static analysis was perfect, the dependence patterns of real
applications are frequently driven by the program input, or experience a phase
change during program execution, meaning that static dependence analysis cannot
be enough.

%speculation necessary
Speculation allows the compiler to overcome static analysis, optimize for an
expected
%/common
case and ignore rare or impossible dependences.  Research into speculation has
shown incredible benefits for the applicability and aggressiveness of
parallelizing transformations.
%Speculative parallelization exploits simplifying assumptions about the input
%code to deliver increased parallel performance.

%speculation problems
Yet, speculative runtime systems face real challenges that prevent their
widespread adoption~\cite{cascaval:08:stmtoy:short, ..}. Even if we assume that
misspeculation never occurs, validating speculative assumptions during a
speculative region may have a large impact on performance.
%
Most speculative systems perform this validation by instrumenting operations
within the parallel region to log or communicate speculative events to a
validation system.  These validation checks add to parallel region latency in
the common case, not only during recovery.
%
Such speculative systems work well when assisted by hardware
extensions~\cite{..}, but yield small speedups, if any, when running on
commodity hardware.
%
%Many proposals speculate low-level properties of the code.
For example, Software Transactional Memories (STMs) present an abstraction that
facilitates speculating the independence of memory transactions.  This reduces
to comparing the read and write sets of adjacent transactions.  As transactions
grow, the number of memory operations within that transaction can become
prohibitively large. Further, instrumenting every memory operation with the
transaction to log or communicate every access---approximately one tenth of all
dynamic instructions---leads to an excessive overhead, even in the absence of
transaction rollbacks.

%privateer
Alternatively, speculative systems can avoid excessive memory speculation by
speculating different properties, allowing for cheap, independent, and
infrequent checking.
%
A prominent work of this class is Privateer~\cite{johnson:12:pldi:short}, a
state-of-the-art Spec-DOALL compiler that significantly reduces the amount of
speculation required compared to a generic software transactional system.
%
The experimental results of this work shows great promise with scalable speedups
on real hardware
%
Privateer partitions loop's memory footprint into several logical heaps/family
according to observed, via profiling, access patterns. Speculating that certain
individual memory access pairs are independent is avoided by just speculating
that the logical heaps remain separated at runtime. Validation of this
separation property only requires worker-local checks, without need for
communication or logging. Nevertheless, separation speculation cannot reason
about memory dependences of non-reducible iteration-private objects. For this
significant set of memory dependences, Privateer employs expensive memory
speculation that requires logging and checks for every single memory operation
on these private objects and occassional communication among workers.
%cheap spec for short-lived or read-only has also been discussed in other spec
%systems such as cluster-doall and corD

Privateer, similarly to other speculative techniques, in the interest of
aggressive parallelization take the extreme of the extreme step of disregarding
static analysis and relying entirely on profiling, losing the understanding of
what needs to be speculated and what not.

The compiler system must balance the enabling effects of speculation with the
runtime cost of validation.

fundamental problem is writes, you always pay for them.
Need to monitor last-writes even with no-spec
reads can be avoided if static analysis can disprove them.
all writes in a transcation have to be spec_writes.
maybe Change the narrative.
maybe the focus should be more on privitization

Counter-intuitive result: using spec (value pred, predictable private) can get
better perf than non-spec (static privitization)

% Privateer has some limitations.

%There is also a question of whether fragile and imprecise static
%analysis will overly pessimize a speculative runtime system.
%Although the indeterminate dependences can be
%removed via speculation, each additional speculative assumption
%adds to the validation overhead.

%STMs represent a natural first step towards speculative support
%systems, since the transactional metaphor resembles the cognitive level of
%compiler writers who focus on automatic parallelization.  However, it
%proves a nightmare for scalable validation of speculative
%properties~\cite{cascaval:08:stmtoy}.


% Why we are better than Privateer?

% Using static analysis to disprove some dependences
% Better static analysis

% (A way to let Enablers work nicely together)
% Make fine-grained separation of private objects and use cheap speculation
% Reduce the process-based runtime spawning overhead
