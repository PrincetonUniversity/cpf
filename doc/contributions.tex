\section{The \name Approach}

\name combines a speculation-aware memory analyzer, enabling
transformations including efficient speculative privatization, and a
parallelization planner into an exploration phase designed to find the
best performing set of parallelization techniques.  This section
discusses the main contributions of this paper, and presents a code
example to underline improvements over
Privateer~\cite{johnson:12:pldi}, a state-of-the-art speculative DOALL
parallelization system.

\subsection{Speculation-Aware Memory Analyzer}


%
Prior techniques, independently apply speculative techniques to
overcome the imprecision of memory analysis, often resorting to
expensive memory speculation.
%
%This work suggests that exposing cheap-to-validate speculative
%assumptions to static analysis can enable removal of memory
%dependences that would otherwise require memory speculation.
%
%This combination yields higher precision than using static analysis
%and these assumptions in a sequence.
%
%By making memory analysis aware of cheap-to-validate speculative
%assumptions, 
%
Instead, this work proposes a speculation-aware memory analyzer that
combines the strengths of static analysis and cheap-to-validate
speculative assumptions.  If memory analysis fails on its own to
resolve an analysis query, then it interprets cheap-to-validate
speculative assumptions as facts ignoring the possibility of
misspeculation.
%
The use of speculation changes the semantics of traditional memory
analysis' answers. It is now required to specify for each answer the
speculative assumptions, if any, that were used in the process.
%
Just applying speculation and then re-using memory analysis would not
have the same effect since the possibility of misspeculation restrains
static analysis.

%When a query is received the memory analyzer tries to resolve it with
%usage of just static analysis. If that fails, it tries to use memory
%analysis with cheap-speculative assumptions.
%If that still fails then it resorts to memory speculation.
%
%
%Memory analysis annotates a PDG with information utilized by the
%decision making process in the rest of the planning phase.

\name's memory analysis is composed of many simple analysis algorithms
that collaboratively respond to queries (\`{a} la
CAF~\cite{johnson:cgo:17}). 
%
The modularity of our static analysis simplifies the addition of
speculation awareness.  Only the analysis algorithms that could
actually benefit from that collaboration need to be extended with a
speculative mode.
%
A monolithic memory analysis would be harder to extend for
speculation-awareness.

In the speculation aware memory analyzer, \name utilizes speculative
assumptions from two profilers, edge profiler (detects biased
branches) and loaded value predictor (predicts loaded values).
%
Exposing other cheap-to-validate speculative assumptions to memory
analysis could also be beneficial.  Such exploration is left for
future work. 
%This paper just stratches the surface of this 

Edge profiling can produce a speculative control flow. This
speculative control flow can be used by memory analysis passes to
handle more queries.
%
Two examples of analysis passes that can benefit from this speculative
information is kill-flow and unique access paths (UAP) analysis
algorithms.  

Kill-flow analysis disproves memory dependences by finding killing
operations along all feasible paths between two operations. If
kill-flow is able to use speculative control flow information, then
the feasible paths might be reduced and kill-flow might be able to
assert absence of a statically non-disprovable memory dependence.

UAP collects a points-to set of values for a pointer stored into a
non-captured memory location (i.e., address never stored into memory
and never passed to an externally defined function). 
%Alias queries related to this memory location produce new alias
%queries for each value stored in this memory location. 
Use of speculative control flow information enables detection of
speculatively dead stores in this set, decreasing it size and thus
simplifying alias queries for this pointer.

%In both examples, without speculative control flow awareness, prior
%speculative parallelization systems would be forced to use expensive
%memory speculation instead.

If memory analysis passes assume that loaded value predictions are
correct, then they can re-interpret a predicted load as a store of the
predicted value. One analysis algorithm that can benefit from that is
again kill-flow. Kill-flow treats the predictable load as a kill
operation (i.e., a store) and can remove certain dependences regarding
memory operations that must-alias with the predicted load's memory
location.


Apart from removal of dependences, the speculation-aware memory
analyzer is also used to characterize dependences.
%and dependent instructions.
%
Traditionally, dependence analysis (static, dynamic or speculative) in
speculative parallelization only attempts to completely remove
dependences.
%
If a dependence cannot be removed even with usage of speculation,
because it is a real dependence that frequently manifests at runtime,
no useful information is provided related to this dependence.
%
The memory analyzer though could still infer some useful property for
this dependence or the dependent instructions.
%
This information is essential to enable certain transformations, such
as the efficient variants of speculative privatization described in
section ~\ref{novel_transf}.

The speculation-aware memory analyzer is queried to populate an
annotated PDG with information utilized by the rest of the planning
phase.

\subsection{Enabling Transformations}

Transformations modify the code to remove parallelization inhibitors.
%
All transformations are split into two parts. The applicability guard
that participates in the planning phase of the compilation and the
actual transformation that is applied if selected in the
transformation phase.
%This scheme seperates the desicion part from the actual
%transformation and allows us to evaluate the cost of each dependence
%separetely and
This separation of decision making and application of transformations
allows \name to choose the most profitable plan instead of applying
all the enabling transformations in a sequence.

%
The applicability guard of a transformation determines, using the
results of the speculation-aware memory analyzer, where the
transformation is applicable and under which assumptions. Assumptions
are speculative information that require validation for the
transformation to be correct. 
%
The output of each applicability guard is collected in a
transformation proposal and is sent to the DOALL
planner~\ref{planner}.
%
The proposal includes for each memory object an estimated handling
cost based on the transformation itself and the validation cost of the
used speculative assumptions.
%
TODO: explain cost here.
%

Enabling transformations address memory, register or/and control
cross-iteration dependences. 
%
%This section focuses on memory related enabling transformations.
%Register and control dependence handling is discussed in 
%~\ref{design_transf}.


\subsubsection{Memory} 
%
\paragraph{Applicability:}
The applicability guard determines which memory objects have certain
properties required by the corresponding transformation.
%
Applicability means that the transformations can address all the
cross-iteration dependences related to this memory object. 
%
%which speculative assumptions need to be validated for the
%transformation to be correct.
%
%Object-centric transformation.  All memory objects need to be handled
%by a transformation.
%
%each access of the memory object should preserve the property
%
%Finally, each transformation
%includes in its proposal the set of speculative assumptions validation
%necessary for each memory object for the transformation applicability
%to be correct.


\paragraph{Transformation Application:} If, during the planning phase,
a transformation is selected for a set of memory objects, then during
the code transformation phase it separates them in an isolated heap
via re-allocation, and adds runtime checks, if needed, to ensure that
all their accesses are contained within this heap.  
%Each transformation separates the memory objects it is selected to
%handle in an isolated heap via
Separation checks are required for memory accesses whose underlying
objects are discovered via profiling.
%Separation checks are sufficient to ensure that the points-to-map is
%correct.
The runtime function for re-allocation of memory objects can be
specialized by each transformation.
%
%Each transformation has its own runtime support for handling its
%objects during execution.
Each heap can have different memory mapping semantics and is handled
differently at commit and at the end of parallel invocation. 
%
Further, some transformations insert additional transformation-specific
checks and other modifications.

The idea of separating memory objects has been explored previously by
Johnson et al. (Privateer~\cite{johnson:12:pldi}).  However, Privateer
employs a monolithic design that entagles classification of memory
objects with memory speculation and other 
%monolithic design of memory object classification entangles
%separation speculation with memory speculation and other
profiling-based information resulting in high unnecessary runtime
overheads (see example in section~\ref{motiv_example}, and performance
analysis in section ~\ref{eval}).
%
By contrast, \name employs a modular and extensible design that
facilitates planning and selection of minimal cost solutions.
%where enabling transformations offer to handle memory objects along
%with estimated costs -offers with costs and the selection happens.
%
Only the selected transformations and their corresponding assumption
validation is applied.  Nothing more.


TODO: add algorithm. All accesses need to respect this property. Every
transformation creates a family with memory objects with the same
properties.  It collects the set of objects that it can handle.



We describe in the next section efficient variants of the speculative
privatization transformation, which constitute contribution of this
paper.  Other enabling transformations that are used in our framework
but have been proposed in prior work are discussed in
section~\ref{design_transf}.

\subsubsection{Novel Transformations}

Privatization: the simple version of this transformation just
ensures the basic privatization property that there are no
cross-iteration data flows for a memory object.

Behavior: Monitor all write accesses of the object and merge write
sets at commit.

Other variants of this transformation express additional properties for
reduced privatization overhead.
%
\begin{itemize}
%
\item Independent.

Additional applicability guard: object has no
loop-carried false dependences

Behavior : No write set monitoring performed. Memory object is shared among parallel workers.
%
%
\item Known Last Iteration Update.

Additional applicability guard:
object has loop-invariant condition for last update within the loop.

Behavior: No write set monitoring performed. The live-out state for
object with this property is the memory state of the last iteration
executed before commit.
%
%
\item Predictable Live-out Content.

Additional applicability guard:
The live-out content of an object can be predicted.
%
%
\item Local Private.

Additional applicability guard: object is
allocated outside the loop, but all its accesses are contained within
the loop execution
%
\end{itemize}


\subsection{DOALL planner}
\label{planner}
\input{planner}

\lstset{basicstyle=\ttfamily, numbers=left, numberstyle=\tiny,
  stepnumber=1, numbersep=5pt}

\begin{figure}[t]
  \centering
  %\begin{tabular}{cc}
  \scriptsize
%\resizebox{0.8\linewidth}{!}{
    \subfloat{
    \begin{minipage}{5cm}
      \input{figures/dijkstra_motivation}
    \end{minipage}
 %   }
%    &
 %    \hspace{1cm}
%\subfloat
%{
%    \begin{minipage}{7cm}
%  %  \includegraphics[scale=0.7]{figures/seq_motivation.pdf}
%
%\begin{itemize}
%\item
%Reuse across iterations of the \textbf{pathcost} array and global variable
%\textbf{dist} creates cross-iteration false dependences that inhibit
%parallelization.
%
%\item
%Privatization enables parallelization of this loop by creating private copies
%of \textbf{pathcost} and \textbf{dist} memory objects for every worker.
%
%\item From prior work, Privateer~\cite{Johnson:12:plid} is the only automatic
%system to support privatization of dynamically allocated objects, like
%\textbf{pathcost}, even in the presence of unrestricted pointers.
%
%\item
%Privatization of these memory objects requires:
%\begin{enumerate}
%\item
%identification of all accesses of these objects
%    within the loop
%\item
%absence of cross-iteration flow
%     dependences on each of these accesses
%\end{enumerate}
%
%\end{itemize}
%
%    \end{minipage}
%}
%\end{tabular}

}
\caption{Sequential \textit{dijkstra} example from MiBench~\cite{}}
%(with dynamic allocation of arrays (static privatization is not applicable anymore). assume that pathcost cannot be proven as non-liveout)
\label{fig:dijkstra_motivation}
\end{figure}

\begin{figure*}[!t]
\centering
\resizebox{0.9\linewidth}{!}{
\subfloat[Privateer~\cite{johnson:12:pdli}]{
  \centering
  \includegraphics[width=0.46\textwidth]{figures/privateer-example-crop}
}
\qquad
\subfloat[This work]{
  \centering
  \includegraphics[width=0.46\textwidth]{figures/perspective-example-crop}
}
}
\caption{Property inference comparison of Privateer with LSD for memory
objects \textit{pathcost} and \textit{dist} of the hot loop of \textit{dijkstra}}
\label{fig:dijkstra_motivation_comparison}
\end{figure*}

\begin{figure*}[!b]
\centering
\scriptsize
\resizebox{0.8\linewidth}{!}{
\subfloat[Privateer~\cite{johnson:12:pdli}]{
  \centering
  \begin{minipage}{8.55cm}
  \input{figures/dijkstra_motivation_checks}
  \end{minipage}
}
\qquad
\qquad
\subfloat[This work]{
  \centering
  \begin{minipage}{7.2cm}
  \input{figures/dijkstra_motivation_checks_our}
  \end{minipage}
}
}
\caption{Source code comparison of Privateer with LSD for parallelized hot loop
of \textit{dijkstra}. Checkpointing occurs every several (long running) loop iterations, thus its
overhead is negligeable for \textit{dijkstra}. Logging and checks
during loop execution dominate the overheads.}
\label{fig:dijkstra_motivation_comparison_source_code}
\end{figure*}



\subsection{Example}
\label{motiv_example}

This example underlines inefficiencies and limitations of prior work and
showcases how the combination of static analysis with cheap-to-validate
speculative assumptions can infer program properties that enable scalable
parallelization.
%
Consider the code in
Figure~\ref{fig:dijkstra_motivation} (taken from MiBench~\cite{} benchmark
dijkstra, used in the evaluation of Privateer~\cite{}).
%
Reuse across iterations of the \textbf{pathcost} array and global variable
\textbf{dist} creates cross-iteration false dependences that inhibit
parallelization.
%
Privatization enables parallelization of this loop by creating private
copies of \textbf{pathcost} and \textbf{dist} memory objects for every
worker.
%
From prior work, Privateer~\cite{johnson:12:pldi} is the only automatic
system to support privatization of dynamically allocated objects, like
\textbf{pathcost}, even in the presence of unrestricted pointers.
%
Figure~\ref{fig:dijkstra_motivation_comparison} compares the property
inference property of Privateer compared to this work.
The difference is that

Figure~\ref{fig:dijkstra_motivation_comparison_source_code} compares the
resulting parallelized versions (in a simplified form) for Privateer and
this work. The code includes all the added checks, logging and handling
live-out overheads. The code changes are marked with the average added
overhead over the useful work of each worker.
It is clear that Privateer introduces a lot of added overhead considerably
limiting its profitability. XXX on the other side ..


Privateer would choose to just do simple privatization with mem spec.
The spec-aware analyzer allows removal of mem spec and efficient
privatization in this case.

\begin{itemize}
\item
Privatization of these memory objects requires:
\begin{enumerate}
\item
identification of all accesses of these objects
    within the loop
\item
absence of cross-iteration flow
     dependences on each of these accesses
\end{enumerate}

\end{itemize}


Remove text from figure 1. Just add some here, the rest has been explained
earlier.
Real dependnecs prevent
DOALL can become applicable if these two objects are proven to have the
private property.

We compare our approach where we combine static analysis with cheap-to-validate
with privateer's monolithic approach that over-speculates and is limited by high
runtime overheads.

We initially present the compilation flow for both approaches, then the
resulting parallelized code and finally the flow of live-in and live-out memory
data.

Whilst the private property is enough for DOALL
Notice that we infer an additional property that improves the profitability
of parallelization.

%Note that anti-dependences are ignored since both systems use
%process-based runtime systems.

For inferring the property that a memory object has the locally-accessed
property, it suffices to identify all accesses of the memory object. If all
these accesses are within the loop then the memory object has the
locally-accessed property.



