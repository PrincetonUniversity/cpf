\section{The \name Approach}

\name combines a speculation-aware memory analyzer, enabling
transformations including efficient speculative privatization, and a
parallelization planner into an exploration phase designed to find the
best performing set of parallelization techniques.  This section
discusses the main contributions of this paper
(sections~\ref{analyzer},\ref{enablers},\ref{planner}), and
presents a code example (section~\ref{motiv_example}) to underline
improvements over Privateer~\cite{johnson:12:pldi}, a state-of-the-art
speculative DOALL parallelization system.

\subsection{Speculation-Aware Memory Analyzer}
\label{analyzer}

%
Prior techniques independently apply speculative techniques to
overcome the imprecision of memory analysis, which often exhibits
excessive use of expensive memory speculation. \{\textxbf{XXX} reword\}
%
%This work suggests that exposing cheap-to-validate speculative
%assumptions to static analysis can enable removal of memory
%dependences that would otherwise require memory speculation.
%
%This combination yields higher precision than using static analysis
%and these assumptions in a sequence.
%
%By making memory analysis aware of cheap-to-validate speculative
%assumptions,
%
Instead, this work proposes a speculation-aware memory analyzer that
combines the strengths of static analysis and cheap-to-validate
speculative assumptions to reduce the need for expensive speculation.
If memory analysis fails on its own to resolve an analysis query, then
it interprets cheap-to-validate speculative assumptions as facts
ignoring the possibility of misspeculation. \{\textbf{XXX} what if the
speculative assumption is not useful to the query?\}
%
The inclusion of speculation changes the semantics of traditional memory
analysis. It is now required to specify for each answer the
speculative assumptions, if any, that were used in the process.
%
Just applying speculation and then re-using \{\textbf{XXX} better word\} memory analysis would not
have the same effect since the possibility of misspeculation restrains
static analysis.

%When a query is received the memory analyzer tries to resolve it with
%usage of just static analysis. If that fails, it tries to use memory
%analysis with cheap-speculative assumptions.
%If that still fails then it resorts to memory speculation.
%
%
%Memory analysis annotates a PDG with information utilized by the
%decision making process in the rest of the planning phase.

\name's memory analysis is composed of many simple analysis algorithms
that collaboratively respond to queries (\`{a} la
CAF~\cite{johnson:cgo:17}).
%
The modularity of our static analysis simplifies the addition of
speculation awareness. Only the analysis algorithms that could
possibly benefit from the collaboration need to be extended with a
speculative mode. \{\textbf{XXX} is it a different mode?\}
%
A monolithic memory analysis would be harder to extend for
speculation awareness.

In the speculation-aware memory analyzer, \name utilizes speculative
assumptions from two profilers: edge profiler (detects biased
branches) and loaded value predictor (predicts loaded values).
%
Exposing other cheap-to-validate speculative assumptions to memory
analysis could also be beneficial.  Such exploration is left for
future work.
%This paper just stratches the surface of this

Edge profiling can produce a speculative control flow. This
speculative control flow can be used by memory analysis passes to
handle more queries.
%
Two examples of analysis passes that can benefit from this speculative
information is kill-flow and unique access paths (UAP) algorithms.
%
Kill-flow analysis disproves memory dependences by finding killing
operations along all feasible paths between two operations.
\{\textbf{XXX} Are "killing operations" common knowledge? \}
If kill-flow is able to use speculative control flow information, then
the feasible paths might be reduced and kill-flow might be able to
assert absence of a statically non-disprovable memory dependence.
%
UAP collects a points-to set of objects for a pointer stored into a
non-captured memory location (i.e., address never stored into memory
and never passed to an externally defined function).
%Alias queries related to this memory location produce new alias
%queries for each value stored in this memory location.
Use of speculative control flow information enables detection of
speculatively dead stores in this set, decreasing its size and thus
simplifying alias queries for this pointer.

%In both examples, without speculative control flow awareness, prior
%speculative parallelization systems would be forced to use expensive
%memory speculation instead.

Regarding value prediction, if memory analysis passes assume that
loaded value predictions are correct, then they can re-interpret a
predicted load as a store of the predicted value. One analysis
algorithm that can benefit from that is again kill-flow. Kill-flow
treats the predictable load as a kill operation (i.e., a store) to any
dominated operation that must-alias with the predicted load's memory
location \{\textbf{XXX} reword this\}.

%Apart from removal of dependences, the speculation-aware memory
%analyzer is also used to characterize dependences.
%%and dependent instructions.
%%
%Traditionally, dependence analysis (static, dynamic or speculative) in
%speculative parallelization only attempts to completely remove
%dependences.
%%
%If a dependence cannot be removed even with usage of speculation,
%because it is a real dependence that frequently manifests at runtime,
%no useful information is provided related to this dependence.
%%
%The memory analyzer though could still infer some useful property for
%this dependence or the dependent instructions.
%%
%This information is essential to enable certain transformations, such
%as the efficient variants of speculative privatization described in
%section ~\ref{novel_transf}.

The speculation-aware memory analyzer is queried to populate a program
dependence graph (PDG) annotated with information utilized by the rest
of the planning phase, namely by enabling transformations and the
planner. Annotations include properties for the dependences and the
dependent instructions.
%Note that traditional dependence analysis (static, dynamic or
%speculative) in speculative parallelization only attempts to
%completely remove dependences, while the speculation-aware memory
%analyzer infers properties for even non-removable ones.
Annotations may include more than one option for the same property if
speculative assumptions are used. \{\textbf{XXX} What is an option?\}
%
Decision making is left for the planner, which can perform global
reasoning.
%The planner is responsible for selecting the most profitable option,
%taking into consideration. Memory analyzer has a limited scope.


\subsection{Enabling Transformations}
\label{enablers}

Transformations modify the code to remove parallelization inhibitors.
%
All transformations are split into two parts. The applicability guard
that participates in the planning phase of the compilation and the
actual transformation that is applied if selected in the
transformation phase.
%This scheme seperates the desicion part from the actual
%transformation and allows us to evaluate the cost of each dependence
%separetely and
This separation of decision making and application of transformations
allows \name to carefully select the most profitable plan instead of
applying all the enabling transformations in a sequence \{\textbf{XXX}
Don't we also apply the transformations in a sequence at the end?\}.

Enabling transformations address memory, register or/and control
cross-iteration dependences.
%
This section focuses on memory related enabling transformations.
Register and control dependence handling is discussed in
section~\ref{design_transf}.


%\subsubsection{Memory}
%
\subsubsection{Applicability:}

%
The applicability guard of a transformation determines, using the
results of the speculation-aware memory analyzer,  which memory
objects have certain properties required by the corresponding
transformation and under which assumptions.
%
Assumptions are speculative information that require validation for
the transformation to be correct, while applicability for a memory
object means that the transformations can address all the
cross-iteration dependences related to this memory object. \{\textbf{XXX}
Pretty unclear what these two sentences means\}
%
The output of each applicability guard is collected in a
transformation proposal which is sent to the DOALL
planner (section~\ref{planner}).
%
The proposal includes for each memory object an estimated handling
cost based on the transformation itself and the validation cost of the
used speculative assumptions.
%
%The cost of each transformation is determined by the cost of the
%transformation itself and the cost of the speculative assumptions
%required for the transformation to be applicable.
%
For simplicity, in this work each transformation and speculation
validation operation is assigned a fixed
%predefined
cost that just ensures a basic ordering among the options. For
example, regarding speculative assumptions, memory speculation has a
extremely high cost, loaded value prediction has a much smaller cost
but not smaller than control speculation. Control speculation has the
lowest cost since its validation does not introduce any overhead.
%The estimated cost computation is very basic and just ensures basic
%ordering among the options.
%
%Every transformation is assigned an arbitrary cost that ensures some
%ordering among transformation. Speculative assumptions is similarly
%computed.
%
For the set of transformations and speculative assumptions in our
framework in the context of DOALL parallelization, simple ordering
proved sufficient \{\textbf{XXX} This may sound contradictory to our
previous statement that we want to avoid the fixed ordering\}.
%
A more complex cost model that would allow more elaborate decision
making is left for future work.

%
%
%which speculative assumptions need to be validated for the
%transformation to be correct.
%
%Object-centric transformation.  All memory objects need to be handled
%by a transformation.
%
%each access of the memory object should preserve the property
%
%Finally, each transformation
%includes in its proposal the set of speculative assumptions validation
%necessary for each memory object for the transformation applicability
%to be correct.

\paragraph{Transformation Application:} If, during the planning phase,
a transformation is selected for a set of memory objects, then during
the code transformation phase the selected transformation separates
these objects in an isolated heap via re-allocation, and adds runtime
checks, if needed, to ensure that all their accesses are contained
within this heap \{\textbf{XXX} What are these heaps and why are they
important?\}.
%Each transformation separates the memory objects it is selected to
%handle in an isolated heap via
Separation checks are required for memory accesses whose underlying
objects are discovered via profiling.
%Separation checks are sufficient to ensure that the points-to-map is
%correct.
The runtime function for re-allocation of memory objects can be
specialized by each transformation.
%
%Each transformation has its own runtime support for handling its
%objects during execution.
Each heap can have different memory mapping semantics and is handled
differently at commit and at the end of parallel invocation.
%
Further, some transformations insert additional
transformation-specific checks and other modifications.
\{\textbf{XXX} Paragraph doesn't have much of a flow, only some facts that
don't seem to work together.\}

The idea of separating memory objects has been explored previously by
Johnson et al. (Privateer~\cite{johnson:12:pldi}).  However, Privateer
employs a monolithic design that entangles classification of memory
objects with memory speculation and other
%monolithic design of memory object classification entangles
%separation speculation with memory speculation and other
profiling-based information, resulting in unnecessarily high runtime
overheads (see example in section~\ref{motiv_example} and performance
analysis in section ~\ref{eval}).
%
By contrast, \name employs a modular and extensible design that
facilitates planning and selection of minimal cost solutions.
%where enabling transformations offer to handle memory objects along
%with estimated costs -offers with costs and the selection happens.
%
Only the selected transformations and validation of their
corresponding speculative assumptions are applied, nothing more than
that \{\textbf{XXX} Why would you apply anything more than necessary?\}.


TODO: add algorithm. All accesses need to respect this property. Every
transformation creates a family with memory objects with the same
properties.  It collects the set of objects that it can handle.


We describe in the next section efficient transformation variants of
speculative privatization, which constitute a contribution of this
paper.  Other enabling transformations that are used in our framework
but have been proposed in prior work are discussed in
section \ref{design_transf}.

\subsubsection{Novel Transformations}
\label{novel_transf}

%Ensuring correct live-out memory state often requires extensive bookkeeping,
%during parallel execution, for the write footprint of private objects. To make
%parallelization more \textit{profitable}, this work expresses more properties
%for private memory objects. Private objects could additionally (a) be
%independent~\cite{ARRAY_privatization} (no loop-carried false dependences); (b)
%have loop-invariant condition for last update within the
%loop~\cite{ARRAY_privatization}; (c) have predictable live-out content;
%%(not found in prior work);
%or (d) have only local accesses (allocated outside the loop, but all
%accesses are contained within the loop execution).
%%
%%Private properties (a), (b) have been explored before in the context of static
%%parallelization~\cite{ARRAY_privatization}, but never before in speculative
%%parallelization systems (maybe in LRPD). No prior work leveraged property (c).
%%
%

Privatization: the simple version of this transformation just
ensures the basic privatization property that there are no
cross-iteration data flows for a memory object.

Behavior: Monitor all write accesses of the object and merge write
sets at commit.

Other variants of this transformation express additional properties for
reduced privatization overhead.
%
\begin{itemize}
%
\item Independent.

Additional applicability guard: object has no
loop-carried false dependences

Behavior : No write set monitoring performed. Memory object is shared among parallel workers.
%
%
\item Known Last Iteration Update.

Additional applicability guard:
object has loop-invariant condition for last update within the loop.

Behavior: No write set monitoring performed. The live-out state for
object with this property is the memory state of the last iteration
executed before commit.
%
%
\item Predictable Live-out Content.

Additional applicability guard:
The live-out content of an object can be predicted.
%
%
\item Local Private.

Additional applicability guard: object is
allocated outside the loop, but all its accesses are contained within
the loop execution
%
\end{itemize}

Table~\ref{tab:priv_types} summarizes how these properties can facilitate more
efficient parallelization compared to just inferring that a memory object is
private. In short, inference of any of these four private properties allows
complete elimination of bookkeeping and access checks. Prior software
speculative systems with extended support of privatization (Privateer~\cite{},
ClusterDoall~\cite{}) are only able to infer the simple private property and
thus always require costly checks or monitoring.

\input{private_types}



\subsection{DOALL planner}
\label{planner}
\input{planner}

\lstset{basicstyle=\ttfamily, numbers=left, numberstyle=\tiny,
  stepnumber=1, numbersep=5pt}

\begin{figure}[t]
  \centering
  %\begin{tabular}{cc}
  \scriptsize
%\resizebox{0.8\linewidth}{!}{
    \subfloat{
    \begin{minipage}{5cm}
      \input{figures/dijkstra_motivation}
    \end{minipage}
 %   }
%    &
 %    \hspace{1cm}
%\subfloat
%{
%    \begin{minipage}{7cm}
%  %  \includegraphics[scale=0.7]{figures/seq_motivation.pdf}
%
%\begin{itemize}
%\item
%Reuse across iterations of the \textbf{pathcost} array and global variable
%\textbf{dist} creates cross-iteration false dependences that inhibit
%parallelization.
%
%\item
%Privatization enables parallelization of this loop by creating private copies
%of \textbf{pathcost} and \textbf{dist} memory objects for every worker.
%
%\item From prior work, Privateer~\cite{Johnson:12:plid} is the only automatic
%system to support privatization of dynamically allocated objects, like
%\textbf{pathcost}, even in the presence of unrestricted pointers.
%
%\item
%Privatization of these memory objects requires:
%\begin{enumerate}
%\item
%identification of all accesses of these objects
%    within the loop
%\item
%absence of cross-iteration flow
%     dependences on each of these accesses
%\end{enumerate}
%
%\end{itemize}
%
%    \end{minipage}
%}
%\end{tabular}

}
\caption{Sequential \textit{dijkstra} example from MiBench~\cite{}}
%(with dynamic allocation of arrays (static privatization is not applicable anymore). assume that pathcost cannot be proven as non-liveout)
\label{fig:dijkstra_motivation}
\end{figure}

\begin{figure*}[!t]
\centering
\resizebox{0.9\linewidth}{!}{
\subfloat[Privateer~\cite{johnson:12:pdli}]{
  \centering
  \includegraphics[width=0.46\textwidth]{figures/privateer-example-crop}
}
\qquad
\subfloat[This work]{
  \centering
  \includegraphics[width=0.46\textwidth]{figures/perspective-example-crop}
}
}
\caption{Property inference comparison of Privateer with LSD for memory
objects \textit{pathcost} and \textit{dist} of the hot loop of \textit{dijkstra}}
\label{fig:dijkstra_motivation_comparison}
\end{figure*}

\begin{figure*}[!b]
\centering
\scriptsize
\resizebox{0.8\linewidth}{!}{
\subfloat[Privateer~\cite{johnson:12:pdli}]{
  \centering
  \begin{minipage}{8.55cm}
  \input{figures/dijkstra_motivation_checks}
  \end{minipage}
}
\qquad
\qquad
\subfloat[This work]{
  \centering
  \begin{minipage}{7.2cm}
  \input{figures/dijkstra_motivation_checks_our}
  \end{minipage}
}
}
\caption{Source code comparison of Privateer with LSD for parallelized hot loop
of \textit{dijkstra}. Checkpointing occurs every several (long running) loop iterations, thus its
overhead is negligeable for \textit{dijkstra}. Logging and checks
during loop execution dominate the overheads.}
\label{fig:dijkstra_motivation_comparison_source_code}
\end{figure*}



\subsection{Example}
\label{motiv_example}

This example underlines inefficiencies and limitations of prior work and
showcases how the combination of static analysis with cheap-to-validate
speculative assumptions can infer program properties that enable scalable
parallelization.
%
Consider the code in
Figure~\ref{fig:dijkstra_motivation} (taken from MiBench~\cite{} benchmark
dijkstra, used in the evaluation of Privateer~\cite{}).
%
Reuse across iterations of the \textbf{pathcost} array and global variable
\textbf{dist} creates cross-iteration false dependences that inhibit
parallelization.
%
Privatization enables parallelization of this loop by creating private
copies of \textbf{pathcost} and \textbf{dist} memory objects for every
worker.
%
From prior work, Privateer~\cite{johnson:12:pldi} is the only automatic
system to support privatization of dynamically allocated objects, like
\textbf{pathcost}, even in the presence of unrestricted pointers.
%
Figure~\ref{fig:dijkstra_motivation_comparison} compares the property
inference property of Privateer compared to this work.
The difference is that

Figure~\ref{fig:dijkstra_motivation_comparison_source_code} compares the
resulting parallelized versions (in a simplified form) for Privateer and
this work. The code includes all the added checks, logging and handling
live-out overheads. The code changes are marked with the average added
overhead over the useful work of each worker.
It is clear that Privateer introduces a lot of added overhead considerably
limiting its profitability. XXX on the other side ..


Privateer would choose to just do simple privatization with mem spec.
The spec-aware analyzer allows removal of mem spec and efficient
privatization in this case.

\begin{itemize}
\item
Privatization of these memory objects requires:
\begin{enumerate}
\item
identification of all accesses of these objects
    within the loop
\item
absence of cross-iteration flow
     dependences on each of these accesses
\end{enumerate}

\end{itemize}


Remove text from figure 1. Just add some here, the rest has been explained
earlier.
Real dependnecs prevent
DOALL can become applicable if these two objects are proven to have the
private property.

We compare our approach where we combine static analysis with cheap-to-validate
with privateer's monolithic approach that over-speculates and is limited by high
runtime overheads.

We initially present the compilation flow for both approaches, then the
resulting parallelized code and finally the flow of live-in and live-out memory
data.

Whilst the private property is enough for DOALL
Notice that we infer an additional property that improves the profitability
of parallelization.

%Note that anti-dependences are ignored since both systems use
%process-based runtime systems.

For inferring the property that a memory object has the locally-accessed
property, it suffices to identify all accesses of the memory object. If all
these accesses are within the loop then the memory object has the
locally-accessed property.



