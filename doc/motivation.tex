% !TEX root = paper.tex
\section{Background and Motivation}
\label{sec:motivation}

\subsection{Background}
% Flow:
% 0. Describe the related work table
% 1. Applicability - the need for privatization, reduction, and speculation
% 2. Previous Attempts to improve efficiency
% 3. Efficiency is still not good

% Problem 1: Static Analysis and Speculation are not used together wisely
% Problem 2: Privatization is expensive
% Combine with the motivating example, the original code
% Use Privateer's statistics to explain why it happens
% Use code example to illustrate what can be done
% Explain how can a programmer infer the overwritten property
% Explain how can a programmer infer the collaboration

% Highlight Privateer as the most competitive prior work


For DOALL parallelization, all loop-carried dependences need to be
addressed. Analyses and enabling transformations are used to disprove and
remove dependences. With more powerful analyses and transformations, a
DOALL parallelization system will have better applicability.

In Table. \ref{tab:related-work}, we compare among related automatic DOALL
software-only systems to understand how prior work evolves over time.
%
Early compilers including SUIF~\cite{blume:96:icpp} and
Polaris~\cite{suif:94:stanford} and improved
systems~\cite{Rus:07:ics,rus:03:hybrid,rauchwerger:99:pds} based on them
mainly focus on scientific programs, especially ones written in
Fortran, thus they lack in support for pointers and dynamically allocated
objects.
%
Recent works like STMlite\cite{mehrara:09:stmlite},
ClusterDOALL\cite{kim:12:cgo} and Privateer\cite{johnson:12:pldi} are
targeted on generic programs and support these dynamic features.

Privatization and reduction are the most important enabling transformations
for DOALL software-only systems. From the table, all the related works
support privatization. However, STMlite and ClusterDOALL don't have support
for reduction, possibly due to the difficulty of extracting reduction for
dynamically allocated objects.

SUIF and Polaris don't use speculative transformations. They use static
analysis at compile time and also leverage run-time analysis to determine,
during run time, whether to use the parallel version or not.
%
The shortcomings of analysis-based systems are obvious. Static analysis
alone is too imprecise to enable aggressive parallelization. With run-time
analysis, the predicates can be too complicated or too expensive to
extract.
%
Speculation, on the other hand, allows the compiler to overcome analysis'
constraints by ignoring rare or impossible dependences and uses validation
and recovery to guarantee correctness. All the recent works have support
for at least some forms of speculation.

Privateer, by using more aggressive speculation, enables more privatization
and reduction than prior systems and becomes the most applicable
speculative systems. Yet, applicability doesn't necessarily translate to
parallel performance. With all kinds of overheads, a parallelized program
yields little speedup or even slowdown. Because of these overheads, the
results of automatic DOALL systems on real hardware are still
underwhelming.

% This paper focuses on DOALL, the most well-studied parallelization paradigm
% in literature. When applicable, DOALL can avoid most communications
% comparing to other paradigms like DOACROSS and DOPIPE and deliver good
% performance in terms of speedup and scalability. To extend the
% applicability of DOALL, prior work has explored various enabling
% transformations like privatization, reduction, and different types of
% speculation and has achieved great applicability even for general purpose
% programs.




%% Previous Attempts to Reduce Runtime Overhead

% There are some attempts to identify and reduce some overheads. Hybrid
% Analysis~\cite{rus:03:hybrid} and Sensitivity Analysis~\cite{Rus:07:ics}
% combine static analysis and run-time analysis to generate cheap predicates
% for memory dependences, which reduce the run-time overhead. Recent
% work~\cite{ctian:2008:micro,johnson:12:pldi,kim:12:cgo} avoids some memory
% speculations by speculating higher-level properties like local objects
% whose validation does not require logging or communication.


\subsection{Two Major Overheads}
% Refer to dijkstra code example
% Use Privateer's hard data to explain how bad it was
In this part, we discuss the results presented in the Privateer paper and
explain the impact of two major overheads, namely excessive use of memory
speculation and expensive privatization. We will also use the code in
Figure~\ref{fig:dijkstra_motivation} as a motivating example (taken from
\texttt{dijkstra} from MiBench~\cite{}, used in the evaluation of
Privateer) to show the opportunities to avoid these overheads.
% %
% Reuse across iterations of the \textbf{pathcost} array and global variable
% \textbf{dist} creates cross-iteration false dependences that inhibit
% parallelization.
% %
% Privatization enables parallelization of this loop by creating private
% copies of \textbf{pathcost} and \textbf{dist} memory objects for every
% worker.

\lstset{basicstyle=\ttfamily, numbers=left, numberstyle=\tiny,
  stepnumber=1, numbersep=5pt}
\begin{figure}[t]
  \centering
  %\begin{tabular}{cc}
  \scriptsize
%\resizebox{0.8\linewidth}{!}{
    \subfloat{
    \begin{minipage}{5cm}
      \input{figures/dijkstra_motivation}
    \end{minipage}
 %   }
%    &
 %    \hspace{1cm}
%\subfloat
%{
%    \begin{minipage}{7cm}
%  %  \includegraphics[scale=0.7]{figures/seq_motivation.pdf}
%
%\begin{itemize}
%\item
%Reuse across iterations of the \textbf{pathcost} array and global variable
%\textbf{dist} creates cross-iteration false dependences that inhibit
%parallelization.
%
%\item
%Privatization enables parallelization of this loop by creating private copies
%of \textbf{pathcost} and \textbf{dist} memory objects for every worker.
%
%\item From prior work, Privateer~\cite{Johnson:12:plid} is the only automatic
%system to support privatization of dynamically allocated objects, like
%\textbf{pathcost}, even in the presence of unrestricted pointers.
%
%\item
%Privatization of these memory objects requires:
%\begin{enumerate}
%\item
%identification of all accesses of these objects
%    within the loop
%\item
%absence of cross-iteration flow
%     dependences on each of these accesses
%\end{enumerate}
%
%\end{itemize}
%
%    \end{minipage}
%}
%\end{tabular}

}
\caption{Sequential \textit{dijkstra} example from MiBench~\cite{}}
%(with dynamic allocation of arrays (static privatization is not applicable anymore). assume that pathcost cannot be proven as non-liveout)
\label{fig:dijkstra_motivation}
\end{figure}


\subsubsection{Excessive Use of Memory Speculation}

By carefully looking into the evaluation results of Privateer, one major
bottleneck, the validation cost for memory speculation, is spotted.
%
Privateer monitors on average (per parallelized program) 23.7 GB for reads
and 18.4 GB for writes. This monitoring wastes up to 45\% of the time of
parallel workers.
%
These overheads are particularly high for \texttt{dijkstra} whose
speedup is limited to only 4.8x on 24 cores.

There have been attempts to reduce this overhead. A type of rudimentary
attempt is shown in ClusterDOALL~\cite{kim:12:cgo}, which uses two
compilers, one based on static analysis and one based on speculation to
identify both opportunities. Other attempts including using peephole
optimizations to remove unnecessary speculations and using static analysis
to generate the PDG before parallelizing it are also implicitly shown
in~\cite{johnson:12:pldi,ctian:2008:micro}. However, there is no work
focusing on a meaningful integration between static analysis and
speculation.

Note that instrumenting writes and reads does not only add overheads, it
also prevents other optimizations. Current speculative systems, including
Privateer, often introduce runtime calls for instrumentation of writes and
reads within inner loops and prevent optimizations like vectorization and
reduce even further the speedup over sequential execution.

\subsubsection{Expensive Privatization}

Interestingly, in benchmarks with no usage of memory speculation, thus no
need to monitor read sets, there are still heavy overheads due to write
sets bookkeeping. For the case of the \texttt{blackscholes}, Privateer
records 4.0 GB of writes (per program execution), and 15\% of the workers'
time is wasted. This overhead is due to privatization and the consequent
live-out value handling.
%
Apart from bookkeeping during loop execution, privatization also introduces
the cost of merging the parallel workers' states during checkpointing.

Prior work has attempted to remove this bookkeeping and merging cost for
live-out objects. Integrated in Polaris, there is a certain analysis
\cite{tu:94:lcpc} to infer some properties of a memory object to avoid
overheads.


\subsection{Motivation}
This work is motivated by this excessive use of memory speculation and
expensive privatization of prior speculative systems that significantly
limits their efficiency.
%
In the next section, we will show that using speculation-aware memory
analyzer in conjuction with efficient privatization allows an efficient and
scalable automatic parallelization while maintaining the state-of-the-art
applicability.


%To make a DOALL automatic on software-only systems, the most important job is to
%remove all loop-carried memory dependences. There are two ways to do it - the
%analysis-based or the speculation-based approach.

% A prominent work of this class is Privateer~\cite{johnson:12:pldi:short}, a
% state-of-the-art Spec-DOALL parallelization system, that exhibits more scalable
% speedups compared to prior work.

% Privateer partitions memory objects into several categories/families according
% to observed access patterns via profiling.  Speculating that certain
% individual memory access pairs are independent is avoided by just speculating
% separation of the families and some other simple properties.  However, detection
% of privatizable memory objects relies solely on memory and control profiling.
% Therefore, validation for a substantial set of memory objects still requires
% expensive logging and checks at every memory access, similarly to STM systems.
% % and occassional communication among workers
% %cheap spec for short-lived or read-only has also been discussed in other spec
% %systems such as cluster-doall and corD

% The analysis-based approach and speculation-based approach are in general
% detached.

% All prior speculative techniques require monitoring of extensive read and write
% sets.

% (even if no checks for reads are needed, still need to monitor write sets.)


%

%the size of the write set is significant (4.0 GB). Workers spent 15\% of their
%time just monitoring all these writes.


%
%TODO: add code example with hidden_delta loop This work nullifies the need for
%instrumention in this loop and enables vectorization.
%


% Using analysis means proving a dependence is not there,
% either for all input or for a specific input set. If a dependence can be
% statically disproved, we don't need to do anything special for it. If a
% dependence can be removed with certain inputs, we can add a predicate before
% executing it and branch out based on the predicate result. Another way to
% resolve dependence is using speculation, we can speculate that a dependence
% never manifests,

% RAW
% The most important type of dependence is the flow (read-after-write RAW)
% dependence. If RAW dependences actually manifest in a loop, the loop is not
% DOALLable without extra transformations. If a dependence cannot be statically
% disproved but never or seldom manifests from profiling information, we can use
% speculation to remove it and recover if manifests.

% RAR
% Not a real dependence.

% WAR
% The anti (write-after-read, WAR) dependence is problemetic when two workers
% don't execute the instruction in order. With privatization, these dependences
% are removed for free because the source where different worker read from and
% write to is splitted in two.

% WAW

% The output (write-after-write, WAW) dependence.

% In a privatization system, the WAW hazard is also removed for free. However,
% for the live-outs (copy-outs) of a loop, the final value of them can be written
% in any iteration, so there needs to be a mechanism to track who writes last.

% For both analysis-based and speculative systems, WAW dependences are in general
% hard to remove. However, with certain property of a memory object, all WAW
% dependences related to that object canbe safely removed. For example, if an
% array is always fully overwritten at the beginning of a loop, we only need to
% take the values from the last iteration.




% Efforts to augment static analysis with low-cost run-time analysis are limited
% to simple cases where a predicate can be extracted outside the loop of
% interest~\cite{hybrid_analysis, suif:94:stanford, polaris}.

%TODO: check if it is only affine loops for hybrid. that's the case for suif and
%polaris
%
%the dependence patterns of real applications are frequently driven by the
%program input, or experience a phase change during program execution

% Overall, current analysis-based parallelizing
% compilers~\cite{campanoni:2012:iscgo, raman:2008:iscgo, suif:94:stanford,
% polaris, sensitivity} when applicable can deliver good predictable speedups, but
% they all suffer from the aforementioned limitations, and consequently fail to
% enable aggressive and scalable parallelization for most general-purpose
% applications.






%Many proposals speculate low-level properties of the code, namely dependences
%between individual operations.
%%
%Such speculative systems work well when assisted by hardware
%extensions~\cite{TLS_papers...}, but yield small speedups, if any, when
%running on commodity hardware.
%%TODO: other software-spec apart from STM, more recent ones ??
%For example, Software Transactional Memories
%(STMs)~\cite{mehrara:09:stmlite} present an abstraction that facilitates
%speculating the independence of memory transactions (i.e., memory
%speculation). Validation requires logging or communication for most of the
%memory accesses within each transaction and becomes prohibitively expensive
%as the size of transaction grows.
%%
%%This reduces to comparing the read and write sets of adjacent transactions.  As
%%transactions grow, the number of memory operations within that transaction can
%%become prohibitively large. Further, instrumenting every memory operation with
%%the transaction to log or communicate every access---approximately one tenth of
%%all dynamic instructions---leads to an excessive overhead, even in the absence
%%of transaction rollbacks.
%
%%privateer
%
%%An alternative approach is to reduce memory
%
%
%Other speculative systems attempt to avoid the excessive memory speculation of
%generic transactional systems by speculating higher-level properties whose
%validation does not require logging or communication.
%%
%A prominent work of this class is Privateer~\cite{johnson:12:pldi:short}, a
%state-of-the-art Spec-DOALL parallelization system, that exhibits more
%scalable speedups compared to prior work.
%%
%Privateer partitions memory objects into several categories/families according
%to observed access patterns via profiling.  Speculating that certain
%individual memory access pairs are independent is avoided by just speculating
%separation of the families and some other simple properties.  However, detection
%of privatizable memory objects relies solely on memory and control profiling.
%Therefore, validation for a substantial set of memory objects still requires
%expensive logging and checks at every memory access, similarly to STM systems.
%% and occassional communication among workers
%%cheap spec for short-lived or read-only has also been discussed in other spec
%%systems such as cluster-doall and corD
%%

%STMLite, privateer, LRPD, ClusterDoall,
%Polaris, CorD, SUIF
%
%use of static analysis
%
%cheap spec techniques usage
%
%privatization support
%
%handling c/c++ complex data structures, pointers
%
%privatization cost
%
%reductions support
%
%scalable results (cores used)

%Table 1 compares thiswork with other existing automatic parallelization systems.
%Table ~\ref{related_work} summarizes comparison with prior work.


%\subsection{Motivational examples}

%% In this section, we present a code example taken from MiBench~\cite{}
%benchmark dijkstra (used in the evaluation of Privateer~\cite{}) to showcase
%how static analysis along with cheap-to-validate speculative assumptions can
%infer high-level program properties and enable scalable parallelization.  % We
%focus on two memory objects that would cause inefficiencies on prior
%parallelization systems.  % For each of these objects, we examine how we can
%tackle DOALL parallelization inhibitors; in particular loop-carried memory
%dependences, and exhibit the multiplicative effect of collaboration in terms of
%analysis accuracy.
%
%First, a quick description of the used static and speculative analyses in our
%example: % \begin{itemize} % \item \textit{Static Analysis} (see
%~\cite{johnson:17:cgo} for more information) % \begin{itemize} % \item
%\textit{Alias Analysis}: an ensemble of analysis algorithms that determine
%whether the footprint of an operation alias the footprint of another operation.
%% \item \textit{Kill-Flow}: searches for killing operations along all feasible
%paths between two operations. It searches blocks which post-dominate the source
%of the queried dependence and dominate the destination.  % \item
%\textit{No-Capture Source}: identifies global variables or allocators whose
%address is never captured. Such objects can only be referenced through
%addresses computed from the object's name. The algorithm, thus, can enumerate,
%transitively, all uses of that object.  % \end{itemize} % \item
%\textit{Speculative Analysis} % \begin{itemize} % %\item \textit{Loop-Invariant
%Loaded Value Prediction}: \item \textit{Value Prediction Speculation~\cite{}}:
%identifies, using value-prediction, profiling the predictable outcome of
%certain instructions.  %cite F.  Gabbay  and  A.  Mendelson.    Can  program
%profiling  supportvalue %prediction?  % \item \textit{Control
%Speculation~\cite{}}: identifies, using edge profiling, speculatively dead code
%and asserts absence of memory dependences to or from speculatively dead
%operations.  %cite W. Y. Chen, S. A. Mahlke, and W. W. Hwu.  Tolerating first
%levelmemory %access latency in high-performance systems % \end{itemize} %
%\end{itemize} %


%\lstset{basicstyle=\ttfamily, numbers=left, numberstyle=\tiny, stepnumber=1,
%numbersep=5pt} \begin{figure*}[t] \centering \scriptsize \subfloat[Sequential
%code (version 0)] { \label{fig:example_nospec} \begin{minipage}{4.5cm}
%\input{figures/example_nospec} \end{minipage} } \subfloat[Modified version 1] {
%\label{fig:example_simplespec} \begin{minipage}{4.5cm}
%\input{figures/example_simplespec} \end{minipage} } \subfloat[Modified version
%2] { \label{fig:example_additive} \begin{minipage}{4.5cm}
%\input{figures/example_additive} \end{minipage} }
%  %\subfloat[Modified version 3] { \label{fig:example_mult}
%  %\begin{minipage}{4.5cm} \input{figures/example_mult} \end{minipage} }
%  \caption{Sequential code examples. The output loop is the parallelization
%target. Assume that arrays \textit{b}, \textit{c} are liveout.} \end{figure*}
%
%\lstset{basicstyle=\ttfamily, numbers=left, numberstyle=\tiny,
%  stepnumber=1, numbersep=5pt}
%\begin{figure*}[t]
%  \centering
%  \scriptsize
%  \subfloat[Parallelized code (version 0)]
%  {
%    \label{fig:example_ver0_spec}
%    \begin{minipage}{4cm}
%      \input{figures/example_ver0_spec}
%    \end{minipage}
%  }
%  \hspace{0.2cm}
%  \subfloat[Modified version 1 - ctrl spec]
%  {
%    \label{fig:example_ver1_spec}
%    \begin{minipage}{4cm}
%      \input{figures/example_ver1_spec}
%    \end{minipage}
%  }
%  \hspace{0.2cm}
%  \subfloat[Modified version 2a - mem spec]
%  {
%    \label{fig:example_ver2a_spec}
%    \begin{minipage}{4cm}
%      \input{figures/example_ver2a_spec}
%    \end{minipage}
%  }
%  \hspace{0.2cm}
%  \subfloat[Modified version 2b - sep spec]
%  {
%    \label{fig:example_ver2b_spec}
%    \begin{minipage}{4cm}
%      \input{figures/example_ver2b_spec}
%    \end{minipage}
%  }
%%  \hspace{0.2cm}
%%  \subfloat[Modified version 3 - mem spec]
%%  {
%%    \label{fig:example_ver3_spec}
%%    \begin{minipage}{4cm}
%%      \input{figures/example_ver3_spec}
%%    \end{minipage}
%%  }
%  \caption{Parallelized code with speculation checks and logging. Parallelized
%loop is in light-grey. Checks and logging are in grey. Assume arrays \textit{b}, \textit{c} are liveout.}
%\end{figure*}
%
%\begin{table*}
%  \include{figures/related-work-tab2}
%  \caption{
%    Comparison of LSD with Automatic DOALL software-only systems on code
%examples. NO: No Overhead, LC: Local inexpensive Checks (no mem Checks or
%bookkeeping), MC: Memory Checks, WL:
%Write Logging
%  }
%  \label{tab:related-work2}
%    \vspace{-5pt}
%\end{table*}


% \lstset{basicstyle=\ttfamily, numbers=left, numberstyle=\tiny,
%   stepnumber=1, numbersep=5pt}

% \begin{figure*}[t]
%   \centering
%   %\begin{tabular}{cc}
%   \scriptsize
%     \subfloat{
%     \begin{minipage}{5cm}
%       \input{figures/dijkstra_motivation}
%     \end{minipage}
%     }
% %    &
%      \hspace{1cm}
% \subfloat
% {
%     \begin{minipage}{7cm}
%   %  \includegraphics[scale=0.7]{figures/seq_motivation.pdf}

% \begin{itemize}
% \item
% Reuse across iterations of the \textbf{pathcost} array and global variable
% \textbf{dist} creates cross-iteration false dependences that inhibit
% parallelization.

% \item
% Privatization enables parallelization of this loop by creating private copies
% of \textbf{pathcost} and \textbf{dist} memory objects for every worker.

% \item From prior work, Privateer~\cite{Johnson:12:plid} is the only automatic
% system to support privatization of dynamically allocated objects, like
% \textbf{pathcost}, even in the presence of unrestricted pointers.

% \item
% Privatization of these memory objects requires:
% \begin{enumerate}
% \item
% identification of all accesses of these objects
%     within the loop
% \item
% absence of cross-iteration flow
%      dependences on each of these accesses
% \end{enumerate}

% \end{itemize}

%     \end{minipage}
% }
% %\end{tabular}

% \label{fig:dijkstra_motivation}
% \caption{Sequential \textit{dijkstra} example from MiBench~\cite{}}
% %(with dynamic allocation of arrays (static privatization is not applicable anymore). assume that pathcost cannot be proven as non-liveout)
% \end{figure*}

% \begin{figure*}
% \centering
% \subfloat[Privateer~\cite{johnson:12:pdli}]{
%   \centering
%   \includegraphics[width=0.46\textwidth]{figures/privateer-example-crop}
% }
% \qquad
% \subfloat[This work]{
%   \centering
%   \includegraphics[width=0.46\textwidth]{figures/perspective-example-crop}
% }
% \label{fig:dijkstra_motivation_comparison}
% \caption{Property inference comparison of Privateer with \name for memory
% objects \textit{pathcost} and \textit{dist} of the hot loop of \textit{dijkstra}}
% \end{figure*}

% \begin{figure*}
% \centering
% \scriptsize
% \subfloat[Privateer~\cite{johnson:12:pdli}]{
%   \centering
%   \begin{minipage}{7.2cm}
%   \input{figures/dijkstra_motivation_checks}
%   \end{minipage}
% }
% \qquad
% \qquad
% \subfloat[This work]{
%   \centering
%   \begin{minipage}{7.2cm}
%   \input{figures/dijkstra_motivation_checks_our}
%   \end{minipage}
% }
% \label{fig:dijkstra_motivation_comparison}
% \caption{Source code comparison of Privateer with LSD for parallelized hot loop
% of \textit{dijkstra}. Checkpointing occurs every several (long running) loop iterations, thus its
% overhead is negligeable for \textit{dijkstra}. Logging and checks
% during loop execution dominate the overheads.}
% \end{figure*}

%\begin{figure*}
%\centering
%\begin{tabular}{c|c|c}
%
%  \hspace{1cm}  &  \hspace{0.7cm}  State-of-the-art spec-DOALL system (Privateer)
%  \hspace{0.7cm} &  \hspace{3cm} This Work \hspace{3cm}
%
%  \\
%  \hline
%  \raisebox{2.8cm}[0pt][0pt]{\rotatebox{90}{Compilation Workflow}}
%  %\raisebox{1cm}[0pt][0pt]{\rotatebox{90}{\parbox{4cm}{Data Level \\ (Logging &
%%Copy-out Cost)}}}
%  &
%  %\includegraphics[width=6cm]{figures/compilation_flow_privateer}
%  %\includegraphics[scale=0.5]{figures/compilation_flow_privateer_ver2}
%  \includegraphics[scale=0.3]{figures/privateer-example-crop}
%  &
%  %\includegraphics[width=6cm]{figures/compilation_flow_lsd}
%  %\includegraphics[scale=0.5]{figures/compilation_flow_lsd}
%  \includegraphics[scale=0.3]{figures/lsd-example-crop}
%
%  \\
%  \hline
%  \rotatebox[origin=c]{90}{Source Code}
%  &
%  \scriptsize
%  %\tiny
%  \subfloat {
%  \begin{minipage}{6.6cm}
%  \input{figures/dijkstra_motivation_checks}
%  \end{minipage}
%  }
%  &
%  \scriptsize
%  %\tiny
%  \subfloat {
%  \begin{minipage}{6cm}
%  \input{figures/dijkstra_motivation_checks_our}
%  \end{minipage}
%  }
%
%  \\
%  \hline
%  \raisebox{1cm}[0pt][0pt]{\rotatebox{90}{Data Flow}}
%  %\raisebox{1cm}[0pt][0pt]{\rotatebox{90}{\parbox{4cm}{Data Level \\ (Logging &
%%Copy-out Cost)}}}
%  &
%  \includegraphics[width=6.5cm]{figures/data_view_privateer}
%  &
%  \includegraphics[width=6cm]{figures/data_view_lsd}
%
%\end{tabular}
%
%\caption{Parallelization of hot loop of \textit{dijkstra} benchmark}
%\label{fig:dijkstra_parallelized}
%\end{figure*}

%\begin{figure*}[t]
%  \centering
%  \scriptsize
%  \subfloat[Sequential dijkstra example]
%  {
%    \label{fig:dijkstra_motivation}
%    \begin{minipage}{4.4cm}
%      \input{figures/dijkstra_motivation}
%    \end{minipage}
%  }
%  \hspace{0.3cm}
%  \subfloat[Parallelized code with state-of-the-art spec-DOALL system (Privateer)]
%  {
%    \label{fig:dijkstra_motivation_checks}
%    \begin{minipage}{6.6cm}
%      \input{figures/dijkstra_motivation_checks}
%    \end{minipage}
%  }
%  \hspace{0.3cm}
%  \subfloat[Parallelized code with minimal overhead (this work)]
%  {
%    \label{fig:dijkstra_motivation_checks}
%    \begin{minipage}{5.4cm}
%      \input{figures/dijkstra_motivation_checks_our}
%    \end{minipage}
%  }
%
%  \caption{Sequential \textit{dijkstra} code and parallelized versions. Function
%worker\_loop is executed by each worker after spawning. Function's inputs
%specify which iterations each worker should run. Checks, logging and copy-out
%operations are in grey. Assume that array \textit{pathcost} cannot be proved as
%non-liveout.}
%
%\end{figure*}


%\lstset{basicstyle=\ttfamily, numbers=left, numberstyle=\tiny,
%  stepnumber=1, numbersep=5pt}
%\begin{figure*}[t]
%  \centering
%  \scriptsize
%  \subfloat[Privateer]
%  {
%    \label{fig:data_view_privateer}
%    \begin{minipage}{7cm}
%      \includegraphics[width=\textwidth]{figures/data_view_privateer}
%    \end{minipage}
%  }
%  \hspace{2cm}
%  \subfloat[This work]
%  {
%    \label{fig:data_view_lsd}
%    \begin{minipage}{7cm}
%      \includegraphics[width=\textwidth]{figures/data_view_lsd}
%    \end{minipage}
%  }
%  \caption{Data view}
%
%\end{figure*}


%
%%showcases how fine-grained collaboration between static analysis and speculative
%%assumptions can infer high-level program properties without the need for
%%expensive memory speculation.
%
%%Dependence has three conditions. We say there is a memorydependence  from
%%instructioni1to  instructioni2iff(alias)the footprint of operationi1may-aliasthe
%%footprint ofi2, and(feasible-path) there is a feasible path of execution
%%fromi1toi2which (no-kill) does not contain an operation which over-writes the
%%common memory footprint. Footprint denotes theset of memory locations read or
%%written by the instruction.
%
%1) global object \textit{g\_qCount}
%
%\textbf{Static analysis and inexpensive speculation in isolation}:
%%
%%Analysis Results:
%Static analysis cannot disprove all loop-carried RAW and WAW dependences on
%accesses of g\_qCount.
%%
%Profile information indicates that the first load of g\_qCount in each iteration
%always returns zero.  Using this information, value prediction removes the
%loop-carried RAW dependence sinking on this load.
%%
%Removal of this dependence prevents usage of memory speculation for this
%particular load.
%%
%Presence of WAW dependences though necessitates privatization of the memory
%object, and value prediction cannot reason about store instructions and cannot
%give any additional information related to output dependences.
%%
%%Cost
%The cost in this case includes the validation overhead for value prediction
%(perform load before loop exits or on backedges and compared predicted value
%with loaded value) and the privatizaition cost (monitor stores participating in
%the WAW dependences to determine last written value). Bookkeping for
%privatization is the dominant cost as it requires updating metadata multiple
%times per loop iteration (given that some stores are within inner loops).
%%dynamic resolution to determine last written value
%
%
%\textbf{Collaboration of static and speculative analysis}:
%%
%This value prediction can be seen as a store before the first load of g\_qCount
%that kills any data flow for this memory object from previous iterations.
%%
%An extended speculative analysis removes, similarly to the first case, the
%loop-carried RAW dependence, but additionally queries alias analysis for
%must-aliasing accesses with the load's address. If these accesses are dominated
%by the load, then loop-carried RAW or WAW dependences from or to these accesses
%can be ignored.
%%
%This remvoes the need to perform dynamic resolution of the last written value;
%the final content of this memory location is predictable.
%%any action to log (for last write) any of these individual memory operations.
%%
%%Interestingly, this case of privatization goes beyond the classical definition
%%of privatization definition~\cite{tu-padua-array-privatization-1994}  that
%%requires that every load of a privatizable element is preceded by a store to
%%the element in the same iteration of the loop. In this scenario, global
%%variable g\_qCount is first loaded at every iteration, a data flow exists.
%%
%%
%The cost in this case only includes the small validation overhead for value
%prediction. There is no bookkeping cost for privatization.
%%
%No prior work could detect and so effectively handle this new case of
%privatization.
%%- privatization cost: none avoid dynamic resolution to determine last written
%%value (live-out value)
%
%%TODO: use this first
%2) global object \textit{iPrev}
%
%- speculative assumption: the branch "if (qHead)" is always taken (control speculation)
%
%- static analysis: alias analysis, killflow, noCaptureGlobal analysis passes
%
%- validation cost: no validation cost for control spec (just misspecs if branch
%  is not taken)
%
%- Using the speculative assumption, killflow analysis can infer that the store
%  in line 15 kills all other accesses of this global
%variable (killed operations are identified by quering alias analysis). Given this
%property, any RAW loop-carried dependence is disproved.  Additionally, static
%analysis can enumerate all uses of this global, since it is not captured, and
%detect that this global is used only within this loop, namely it is not a
%live-out.  Thus, there is no need to log stores and keep track of the last
%written value to it.
%
%%3) TODO: example with blackscholes
%
%For all the above memory objects, Privateer~\cite{}, the state-of-the-art DOALL
%system that we mainly compare against, would require expensive logging on most
%of their accesses,
%%either for validation checks or for identifying who wrote last what
%yielding sub-optimal speedups as clearly exhibited by our experimental results
%in section ~\ref{eval}.
%%all these objects are classified as privatizable by Privateer
%
%Note that our framework is not limited to static global allocations.  It can
%handle linked or recursive data structures, pointers,type  casts,  and  dynamic
%allocation.
%
%%use alvinn for value pred + alias analysis
%
%%Note that WAR dependences can be ignored thanks to the process-based runtime
%%system.


